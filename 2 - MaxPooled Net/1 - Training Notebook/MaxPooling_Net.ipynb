{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaxPooling Net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Eii-wqfL9p",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we fully train, in an end-to-end manner, the architectures designed in the previous notebook: *Reduce dimensionality: architectures.ipynb*.\n",
        "As a reminder, the end-to-end training procedure gives  an approx. 92% testing acc on the legacy AnalogNet architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3gIO01y1Vxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################################\n",
        "# TRAINING HYPERPARAMETERS\n",
        "#############################################\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 100\n",
        "LR = 0.001\n",
        "\n",
        "# Output binarization\n",
        "MAX_BIN_RATE = 1000\n",
        "\n",
        "# Define regularizers\n",
        "ROUNDING_STEP_CONV = 0.25\n",
        "ROUNDING_STEP_BIAS = 1.\n",
        "\n",
        "REG_CONSTANT = 25."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfW6PmchnzBZ",
        "colab_type": "text"
      },
      "source": [
        "# 0. Import Data / Utils functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOSeDIXLkyA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DPzNy10lPFL",
        "colab_type": "code",
        "outputId": "a07b1c0f-40d2-41f7-a8ad-39443ea13d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Simulate an input binarization\n",
        "x_train = np.minimum(x_train, 100) // 100 * 120\n",
        "x_test = np.minimum(x_test, 100) // 100 * 120"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5XktsXCzUEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customRegularizerConv(x):\n",
        "  return tf.math.cos(2/ROUNDING_STEP_CONV*np.pi*(x-ROUNDING_STEP_CONV/2))+1.\n",
        "\n",
        "def customRegularizerBias(x):\n",
        "  return tf.math.cos(2/ROUNDING_STEP_BIAS*np.pi*(x-ROUNDING_STEP_BIAS/2))+1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pft1QBbDxQe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_accuracy_bin_rate(bin_rate_feed):\n",
        "  accs = np.zeros(x_test.shape[0] // BATCH_SIZE)\n",
        "  for i in range(x_test.shape[0] // BATCH_SIZE):\n",
        "    start = i * BATCH_SIZE\n",
        "    stop = start + BATCH_SIZE\n",
        "    \n",
        "    xs = np.expand_dims(x_test[start:stop],-1)\n",
        "    ys = y_test[start:stop]\n",
        "    \n",
        "    current_acc = sess.run(acc_op,\n",
        "                       feed_dict={in_image_ph: xs,\n",
        "                                  gt_label_ph: ys,\n",
        "                                  bin_rate_ph: bin_rate_feed})\n",
        "    accs[i] = current_acc\n",
        "  \n",
        "  print('Testing Acc.: {}'.format(\n",
        "        accs.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbkOpXp0tx5_"
      },
      "source": [
        "# 1. Network definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qQzvvIWtx6C"
      },
      "source": [
        "## 1.1 Network Definition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VWmyhiDqtx6F",
        "colab": {}
      },
      "source": [
        "def binarize_tensor_differentiable_one_thresh(input, thresh, bin_rate):\n",
        "  return tf.nn.sigmoid(bin_rate*(input - thresh))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l-gNPU8Stx6U",
        "colab": {}
      },
      "source": [
        "def network(input, bin_rate_ph, thresh):\n",
        "  # Convolution\n",
        "  conv1 = slim.conv2d(input, 4, [3, 3], rate=1, activation_fn=tf.nn.relu,\n",
        "                     padding='SAME', scope='conv1')\n",
        "  \n",
        "\n",
        "  # DIMENSIONALITY REDUCTION:\n",
        "  #  avg or max pooling or sampling or no pooling?\n",
        "  conv1 = slim.max_pool2d(conv1, [2, 2], \n",
        "                         stride=[2, 2], padding='SAME')\n",
        "  \n",
        "  # Second conv layer\n",
        "  conv2 = slim.conv2d(conv1, 8, [3, 3], rate=1, activation_fn=None,\n",
        "                      biases_initializer=None,\n",
        "                      padding='SAME', scope='conv2')\n",
        "  \n",
        "  # Simulating output binarisation\n",
        "  conv2_bin = binarize_tensor_differentiable_one_thresh(conv2,\n",
        "                                                        thresh, bin_rate_ph)\n",
        "  \n",
        "  # Sum pooling\n",
        "  pool = slim.avg_pool2d(conv2_bin, [9, 9], \n",
        "                         stride=[9, 9], padding='SAME') * 9*9\n",
        "  # Flatten + dense\n",
        "  flat = tf.layers.flatten(pool)\n",
        "  dense = tf.layers.dense(flat, 50, name='dense1', activation=tf.nn.relu)\n",
        "  out = tf.layers.dense(dense, 10, name='dense2')\n",
        "  \n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6HD1MXtBtx6Y",
        "colab": {}
      },
      "source": [
        "## Define the graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "in_image_ph = tf.placeholder(tf.float32, [BATCH_SIZE,28,28,1])\n",
        "bin_rate_ph = tf.placeholder(tf.float32, ())\n",
        "gt_label_ph = tf.placeholder(tf.uint8)\n",
        "\n",
        "thresh = tf.Variable(3+tf.random.normal([8]), name='out_thresholds')\n",
        "\n",
        "out_label_op = network(in_image_ph, bin_rate_ph, thresh)\n",
        "\n",
        "pred_op = tf.dtypes.cast(\n",
        "            tf.keras.backend.argmax(out_label_op),\n",
        "            tf.uint8)\n",
        "\n",
        "loss_op = tf.reduce_mean(\n",
        "          tf.keras.backend.sparse_categorical_crossentropy(gt_label_ph,\n",
        "                                                           out_label_op,\n",
        "                                                           from_logits=True))\n",
        "\n",
        "acc_op = tf.contrib.metrics.accuracy(gt_label_ph, pred_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyV0Sk4Stx6e",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XTA5ncNgtx6k",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope('conv1', reuse=True) as scope_conv:\n",
        "  w1 = tf.get_variable('weights')\n",
        "  b1 = tf.get_variable('biases')\n",
        "with tf.variable_scope('conv2', reuse=True) as scope_conv:\n",
        "  w2 = tf.get_variable('weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGJg8oMatx6q",
        "colab": {}
      },
      "source": [
        "params_w1 = np.prod(([int(e) for e in w1.shape]))\n",
        "params_b1 = np.prod(([int(e) for e in b1.shape]))\n",
        "params_w2 = np.prod(([int(e) for e in w2.shape]))\n",
        "params_t = np.prod(([int(e) for e in thresh.shape]))\n",
        "params_total = params_w1 + params_b1 + params_w2 + params_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2FohB3Kztx6v",
        "colab": {}
      },
      "source": [
        "reg_losses = params_w1 *tf.reduce_mean(customRegularizerConv(w1))\n",
        "reg_losses += params_b1 *tf.reduce_mean(customRegularizerBias(b1))\n",
        "reg_losses += params_w2 *tf.reduce_mean(customRegularizerConv(w2))\n",
        "reg_losses += params_t *tf.reduce_mean(customRegularizerBias(thresh))\n",
        "reg_losses *= 1/params_total\n",
        "\n",
        "reg_factor_ph = tf.placeholder(tf.float32)\n",
        "loss_with_reg_op = loss_op + reg_factor_ph * reg_losses\n",
        "\n",
        "lr_ph = tf.placeholder(tf.float32)\n",
        "\n",
        "opt_with_reg = tf.train.AdamOptimizer(learning_rate=lr_ph, name='Adam_reg')\n",
        "opt_with_reg_op = opt_with_reg.minimize(loss_with_reg_op)\n",
        "\n",
        "sess.run(tf.variables_initializer(opt_with_reg.variables()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t0ImfiSftx60"
      },
      "source": [
        "## 1.2 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RVzK5oJ9tx62",
        "colab": {}
      },
      "source": [
        "# Previous schedules:\n",
        "  if epoch < EPOCHS * 2:\n",
        "    lr_feed = LR\n",
        "    reg_factor_feed = 0.\n",
        "    bin_rate_feed = 1.\n",
        "  elif epoch < EPOCHS * 4:\n",
        "    lr_feed = LR / 2.\n",
        "    reg_factor_feed = 0\n",
        "    bin_rate_feed = adaptative_factor(epoch - EPOCHS * 2, EPOCHS * 2)\n",
        "    bin_rate_feed = MAX_BIN_RATE*bin_rate_feed + 1\n",
        "  else:\n",
        "    lr_feed = LR / 4.\n",
        "    reg_factor_feed = adaptative_factor(epoch - EPOCHS * 4, EPOCHS * 2)\n",
        "    reg_factor_feed *= REG_CONSTANT\n",
        "    bin_rate_feed = MAX_BIN_RATE + 1\n",
        "    \n",
        "# Long, brutal training, reg then bin\n",
        "for epoch in range(EPOCHS*12):\n",
        "  if epoch < EPOCHS * 4:\n",
        "    lr_feed = LR\n",
        "    reg_factor_feed = 0.\n",
        "    bin_rate_feed = 1.\n",
        "  elif epoch < EPOCHS * 8:\n",
        "    lr_feed = LR / 2.\n",
        "    #reg_factor_feed = adaptative_factor(epoch - EPOCHS * 4, EPOCHS * 4)\n",
        "    reg_factor_feed = REG_CONSTANT\n",
        "    bin_rate_feed = 1.\n",
        "  else:\n",
        "    lr_feed = LR / 4.\n",
        "    reg_factor_feed = REG_CONSTANT\n",
        "    #bin_rate_feed = adaptative_factor(epoch - EPOCHS * 8, EPOCHS * 4)\n",
        "    bin_rate_feed = MAX_BIN_RATE + 1\n",
        "\n",
        "# Long, brutal training, bin then reg\n",
        "for epoch in range(EPOCHS*12):\n",
        "  if epoch < EPOCHS * 4:\n",
        "    lr_feed = LR\n",
        "    reg_factor_feed = 0.\n",
        "    bin_rate_feed = 1.\n",
        "  elif epoch < EPOCHS * 8:\n",
        "    lr_feed = LR / 2.\n",
        "    #reg_factor_feed = adaptative_factor(epoch - EPOCHS * 4, EPOCHS * 4)\n",
        "    reg_factor_feed = 0\n",
        "    bin_rate_feed = MAX_BIN_RATE + 1\n",
        "  else:\n",
        "    lr_feed = LR / 4.\n",
        "    reg_factor_feed = REG_CONSTANT\n",
        "    #bin_rate_feed = adaptative_factor(epoch - EPOCHS * 8, EPOCHS * 4)\n",
        "    bin_rate_feed = MAX_BIN_RATE + 1\n",
        "    \n",
        "# binarization only (without custom reg)\n",
        "for epoch in range(EPOCHS*8):\n",
        "  reg_factor_feed = 0\n",
        "  if epoch < EPOCHS * 4:\n",
        "    lr_feed = LR\n",
        "    bin_rate_feed = 1.\n",
        "  else:\n",
        "    lr_feed = LR / 2.\n",
        "    bin_rate_feed = MAX_BIN_RATE\n",
        "    \n",
        "# custom reg only (without binarization)\n",
        "for epoch in range(EPOCHS*8):\n",
        "  bin_rate_feed = 1.\n",
        "  if epoch < EPOCHS * 4:\n",
        "    lr_feed = LR\n",
        "    reg_factor_feed = 0\n",
        "  else:\n",
        "    lr_feed = LR / 2.\n",
        "    reg_factor_feed = REG_CONSTANT\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "371ad2a7-a7ac-4968-8fe7-ad035a51d5d2",
        "id": "GkheL2uItx69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Long, brutal training, bin then reg\n",
        "for epoch in range(EPOCHS*12):\n",
        "  if epoch < EPOCHS * 4:\n",
        "    lr_feed = LR\n",
        "    reg_factor_feed = 0.\n",
        "    bin_rate_feed = 1.\n",
        "  elif epoch < EPOCHS * 8:\n",
        "    lr_feed = LR / 2.\n",
        "    #reg_factor_feed = adaptative_factor(epoch - EPOCHS * 4, EPOCHS * 4)\n",
        "    reg_factor_feed = 0\n",
        "    bin_rate_feed = MAX_BIN_RATE + 1\n",
        "  else:\n",
        "    lr_feed = LR / 4.\n",
        "    reg_factor_feed = REG_CONSTANT\n",
        "    #bin_rate_feed = adaptative_factor(epoch - EPOCHS * 8, EPOCHS * 4)\n",
        "    bin_rate_feed = MAX_BIN_RATE + 1\n",
        "      \n",
        "  random_perm = np.random.permutation(x_train.shape[0])\n",
        "  losses = np.zeros(x_train.shape[0] // BATCH_SIZE)\n",
        "  for i in range(x_train.shape[0] // BATCH_SIZE):\n",
        "    start = i * BATCH_SIZE\n",
        "    stop = start + BATCH_SIZE\n",
        "    selected = random_perm[start:stop]\n",
        "    \n",
        "    xs = np.expand_dims(x_train[selected],-1)\n",
        "    ys = y_train[selected]\n",
        "    \n",
        "    _, current_loss = sess.run([opt_with_reg_op, loss_with_reg_op],\n",
        "                       feed_dict={in_image_ph: xs,\n",
        "                                  gt_label_ph: ys,\n",
        "                                  lr_ph: lr_feed,\n",
        "                                  reg_factor_ph: reg_factor_feed,\n",
        "                                  bin_rate_ph: bin_rate_feed})\n",
        "\n",
        "    losses[i] = current_loss\n",
        "  \n",
        "  print('Epoch {} completed, average training loss is {}'.format(\n",
        "          epoch+1, losses.mean()))\n",
        "  test_accuracy_bin_rate(bin_rate_feed)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed, average training loss is 1.551198027531306\n",
            "Testing Acc.: 0.8576999998092651\n",
            "Epoch 2 completed, average training loss is 0.36757758622368175\n",
            "Testing Acc.: 0.9145999997854233\n",
            "Epoch 3 completed, average training loss is 0.2679368135581414\n",
            "Testing Acc.: 0.9328000050783157\n",
            "Epoch 4 completed, average training loss is 0.21753744778533776\n",
            "Testing Acc.: 0.9445000040531158\n",
            "Epoch 5 completed, average training loss is 0.19055040993417302\n",
            "Testing Acc.: 0.9460000038146973\n",
            "Epoch 6 completed, average training loss is 0.174289295108368\n",
            "Testing Acc.: 0.949200005531311\n",
            "Epoch 7 completed, average training loss is 0.1609409128812452\n",
            "Testing Acc.: 0.9507000070810318\n",
            "Epoch 8 completed, average training loss is 0.15221682044056556\n",
            "Testing Acc.: 0.9533000057935714\n",
            "Epoch 9 completed, average training loss is 0.1457593734872838\n",
            "Testing Acc.: 0.9576000040769577\n",
            "Epoch 10 completed, average training loss is 0.13857365472552677\n",
            "Testing Acc.: 0.9563000029325486\n",
            "Epoch 11 completed, average training loss is 0.1334119416742275\n",
            "Testing Acc.: 0.9603000056743621\n",
            "Epoch 12 completed, average training loss is 0.12964320736005902\n",
            "Testing Acc.: 0.9580000054836273\n",
            "Epoch 13 completed, average training loss is 0.1258098764376094\n",
            "Testing Acc.: 0.9633000057935714\n",
            "Epoch 14 completed, average training loss is 0.1226238182435433\n",
            "Testing Acc.: 0.9625000023841858\n",
            "Epoch 15 completed, average training loss is 0.11965165200798462\n",
            "Testing Acc.: 0.9647000056505203\n",
            "Epoch 16 completed, average training loss is 0.11641217194187145\n",
            "Testing Acc.: 0.9649000054597855\n",
            "Epoch 17 completed, average training loss is 0.11571537788646917\n",
            "Testing Acc.: 0.9626000052690507\n",
            "Epoch 18 completed, average training loss is 0.11069282161692778\n",
            "Testing Acc.: 0.965000006556511\n",
            "Epoch 19 completed, average training loss is 0.10918233506381511\n",
            "Testing Acc.: 0.9656000071763993\n",
            "Epoch 20 completed, average training loss is 0.10614481261465698\n",
            "Testing Acc.: 0.9679000043869018\n",
            "Epoch 21 completed, average training loss is 0.10382845641113818\n",
            "Testing Acc.: 0.9560000056028366\n",
            "Epoch 22 completed, average training loss is 0.10267004296028366\n",
            "Testing Acc.: 0.9686000061035156\n",
            "Epoch 23 completed, average training loss is 0.10123043004733821\n",
            "Testing Acc.: 0.9682000052928924\n",
            "Epoch 24 completed, average training loss is 0.09764929480695476\n",
            "Testing Acc.: 0.968300005197525\n",
            "Epoch 25 completed, average training loss is 0.09806791725568473\n",
            "Testing Acc.: 0.970900006890297\n",
            "Epoch 26 completed, average training loss is 0.09599316034621248\n",
            "Testing Acc.: 0.9650000059604644\n",
            "Epoch 27 completed, average training loss is 0.09560080336096387\n",
            "Testing Acc.: 0.970100005865097\n",
            "Epoch 28 completed, average training loss is 0.09125939398227881\n",
            "Testing Acc.: 0.9719000077247619\n",
            "Epoch 29 completed, average training loss is 0.09353099248992901\n",
            "Testing Acc.: 0.9674000054597854\n",
            "Epoch 30 completed, average training loss is 0.09079657032464941\n",
            "Testing Acc.: 0.9696000069379807\n",
            "Epoch 31 completed, average training loss is 0.09115772995709752\n",
            "Testing Acc.: 0.9721000093221664\n",
            "Epoch 32 completed, average training loss is 0.08656339874413485\n",
            "Testing Acc.: 0.9700000077486038\n",
            "Epoch 33 completed, average training loss is 0.0878251286316663\n",
            "Testing Acc.: 0.9696000075340271\n",
            "Epoch 34 completed, average training loss is 0.08737045912537723\n",
            "Testing Acc.: 0.9647000056505203\n",
            "Epoch 35 completed, average training loss is 0.0851143726396064\n",
            "Testing Acc.: 0.9697000068426133\n",
            "Epoch 36 completed, average training loss is 0.08478168469853699\n",
            "Testing Acc.: 0.9687000066041946\n",
            "Epoch 37 completed, average training loss is 0.08349719140989086\n",
            "Testing Acc.: 0.973600006699562\n",
            "Epoch 38 completed, average training loss is 0.0842711176816374\n",
            "Testing Acc.: 0.9711000072956085\n",
            "Epoch 39 completed, average training loss is 0.08222585327302416\n",
            "Testing Acc.: 0.9726000082492828\n",
            "Epoch 40 completed, average training loss is 0.08015373629905904\n",
            "Testing Acc.: 0.9721000075340271\n",
            "Epoch 41 completed, average training loss is 0.08041314948427801\n",
            "Testing Acc.: 0.9724000078439713\n",
            "Epoch 42 completed, average training loss is 0.07877200859288375\n",
            "Testing Acc.: 0.9734000074863434\n",
            "Epoch 43 completed, average training loss is 0.08005802298275133\n",
            "Testing Acc.: 0.972900008559227\n",
            "Epoch 44 completed, average training loss is 0.0794667076979143\n",
            "Testing Acc.: 0.973500007390976\n",
            "Epoch 45 completed, average training loss is 0.07667280863039196\n",
            "Testing Acc.: 0.9739000076055526\n",
            "Epoch 46 completed, average training loss is 0.07843182405922562\n",
            "Testing Acc.: 0.9735000056028366\n",
            "Epoch 47 completed, average training loss is 0.07755118156395231\n",
            "Testing Acc.: 0.9742000079154969\n",
            "Epoch 48 completed, average training loss is 0.07647731146309525\n",
            "Testing Acc.: 0.9719000077247619\n",
            "Epoch 49 completed, average training loss is 0.07588252157671377\n",
            "Testing Acc.: 0.9731000077724457\n",
            "Epoch 50 completed, average training loss is 0.07545922018044318\n",
            "Testing Acc.: 0.9726000094413757\n",
            "Epoch 51 completed, average training loss is 0.07419831072057907\n",
            "Testing Acc.: 0.9717000085115433\n",
            "Epoch 52 completed, average training loss is 0.07359709199673185\n",
            "Testing Acc.: 0.970900006890297\n",
            "Epoch 53 completed, average training loss is 0.07298139113544796\n",
            "Testing Acc.: 0.9717000079154968\n",
            "Epoch 54 completed, average training loss is 0.07483881685417146\n",
            "Testing Acc.: 0.9719000065326691\n",
            "Epoch 55 completed, average training loss is 0.07197537420278725\n",
            "Testing Acc.: 0.9728000080585479\n",
            "Epoch 56 completed, average training loss is 0.07048652141122147\n",
            "Testing Acc.: 0.9722000062465668\n",
            "Epoch 57 completed, average training loss is 0.07002618406200782\n",
            "Testing Acc.: 0.9743000108003617\n",
            "Epoch 58 completed, average training loss is 0.07031422967556863\n",
            "Testing Acc.: 0.9740000057220459\n",
            "Epoch 59 completed, average training loss is 0.06942802683217451\n",
            "Testing Acc.: 0.9725000059604645\n",
            "Epoch 60 completed, average training loss is 0.07088261894416065\n",
            "Testing Acc.: 0.974500008225441\n",
            "Epoch 61 completed, average training loss is 0.0697077040739047\n",
            "Testing Acc.: 0.9758000087738037\n",
            "Epoch 62 completed, average training loss is 0.06872986826347187\n",
            "Testing Acc.: 0.9723000067472458\n",
            "Epoch 63 completed, average training loss is 0.06904958214998866\n",
            "Testing Acc.: 0.9736000096797943\n",
            "Epoch 64 completed, average training loss is 0.06787420052452944\n",
            "Testing Acc.: 0.9717000061273575\n",
            "Epoch 65 completed, average training loss is 0.06660427140460039\n",
            "Testing Acc.: 0.9744000065326691\n",
            "Epoch 66 completed, average training loss is 0.06783427362563088\n",
            "Testing Acc.: 0.9747000086307526\n",
            "Epoch 67 completed, average training loss is 0.06621762812370434\n",
            "Testing Acc.: 0.976300008893013\n",
            "Epoch 68 completed, average training loss is 0.06584649159456603\n",
            "Testing Acc.: 0.973900009393692\n",
            "Epoch 69 completed, average training loss is 0.06528899666465197\n",
            "Testing Acc.: 0.9752000063657761\n",
            "Epoch 70 completed, average training loss is 0.06678663143965725\n",
            "Testing Acc.: 0.9757000076770782\n",
            "Epoch 71 completed, average training loss is 0.06510151258825014\n",
            "Testing Acc.: 0.9741000056266784\n",
            "Epoch 72 completed, average training loss is 0.06638181702389072\n",
            "Testing Acc.: 0.9752000057697296\n",
            "Epoch 73 completed, average training loss is 0.06538473112780291\n",
            "Testing Acc.: 0.9740000081062317\n",
            "Epoch 74 completed, average training loss is 0.06388677046944698\n",
            "Testing Acc.: 0.9751000094413758\n",
            "Epoch 75 completed, average training loss is 0.06563232028701653\n",
            "Testing Acc.: 0.9718000078201294\n",
            "Epoch 76 completed, average training loss is 0.06390504437033087\n",
            "Testing Acc.: 0.9766000068187713\n",
            "Epoch 77 completed, average training loss is 0.06517462680581958\n",
            "Testing Acc.: 0.9781000089645385\n",
            "Epoch 78 completed, average training loss is 0.06361573695205153\n",
            "Testing Acc.: 0.9734000056982041\n",
            "Epoch 79 completed, average training loss is 0.06385125260955343\n",
            "Testing Acc.: 0.9758000075817108\n",
            "Epoch 80 completed, average training loss is 0.06244592237325075\n",
            "Testing Acc.: 0.9748000073432922\n",
            "Epoch 81 completed, average training loss is 0.06261553928721696\n",
            "Testing Acc.: 0.9778000062704086\n",
            "Epoch 82 completed, average training loss is 0.06376961519864077\n",
            "Testing Acc.: 0.9751000070571899\n",
            "Epoch 83 completed, average training loss is 0.06274839896941557\n",
            "Testing Acc.: 0.9742000067234039\n",
            "Epoch 84 completed, average training loss is 0.06126588516364184\n",
            "Testing Acc.: 0.9725000047683716\n",
            "Epoch 85 completed, average training loss is 0.06359124461926209\n",
            "Testing Acc.: 0.9755000072717667\n",
            "Epoch 86 completed, average training loss is 0.062320716946851464\n",
            "Testing Acc.: 0.9782000058889389\n",
            "Epoch 87 completed, average training loss is 0.0608464284784471\n",
            "Testing Acc.: 0.9752000093460083\n",
            "Epoch 88 completed, average training loss is 0.06204037301009521\n",
            "Testing Acc.: 0.9759000045061111\n",
            "Epoch 89 completed, average training loss is 0.06207128612557426\n",
            "Testing Acc.: 0.9750000077486038\n",
            "Epoch 90 completed, average training loss is 0.05989186175904858\n",
            "Testing Acc.: 0.9741000056266784\n",
            "Epoch 91 completed, average training loss is 0.06019520616702115\n",
            "Testing Acc.: 0.976400009393692\n",
            "Epoch 92 completed, average training loss is 0.059559315755808105\n",
            "Testing Acc.: 0.9743000030517578\n",
            "Epoch 93 completed, average training loss is 0.06032495505642146\n",
            "Testing Acc.: 0.9763000077009201\n",
            "Epoch 94 completed, average training loss is 0.06137318492168561\n",
            "Testing Acc.: 0.9755000066757202\n",
            "Epoch 95 completed, average training loss is 0.059169445134078465\n",
            "Testing Acc.: 0.975000006556511\n",
            "Epoch 96 completed, average training loss is 0.06009670619193154\n",
            "Testing Acc.: 0.9737000060081482\n",
            "Epoch 97 completed, average training loss is 0.06010166464218249\n",
            "Testing Acc.: 0.9731000059843063\n",
            "Epoch 98 completed, average training loss is 0.06019199368078262\n",
            "Testing Acc.: 0.9768000066280365\n",
            "Epoch 99 completed, average training loss is 0.057397363466055444\n",
            "Testing Acc.: 0.9729000091552734\n",
            "Epoch 100 completed, average training loss is 0.060547780762814606\n",
            "Testing Acc.: 0.9777000069618225\n",
            "Epoch 101 completed, average training loss is 0.05895971279280881\n",
            "Testing Acc.: 0.9772000056505203\n",
            "Epoch 102 completed, average training loss is 0.05869273964548483\n",
            "Testing Acc.: 0.9720000064373017\n",
            "Epoch 103 completed, average training loss is 0.059028728227131066\n",
            "Testing Acc.: 0.9761000061035157\n",
            "Epoch 104 completed, average training loss is 0.05831622725352645\n",
            "Testing Acc.: 0.9775000089406967\n",
            "Epoch 105 completed, average training loss is 0.05577480262533451\n",
            "Testing Acc.: 0.974100006222725\n",
            "Epoch 106 completed, average training loss is 0.05833281128822516\n",
            "Testing Acc.: 0.974200005531311\n",
            "Epoch 107 completed, average training loss is 0.05909015302468712\n",
            "Testing Acc.: 0.9784000062942505\n",
            "Epoch 108 completed, average training loss is 0.05778892853762954\n",
            "Testing Acc.: 0.9742000061273575\n",
            "Epoch 109 completed, average training loss is 0.05788613321337228\n",
            "Testing Acc.: 0.9767000085115433\n",
            "Epoch 110 completed, average training loss is 0.05717845909530297\n",
            "Testing Acc.: 0.9781000071763992\n",
            "Epoch 111 completed, average training loss is 0.05694110970168064\n",
            "Testing Acc.: 0.9762000072002411\n",
            "Epoch 112 completed, average training loss is 0.05916400873684324\n",
            "Testing Acc.: 0.9751000094413758\n",
            "Epoch 113 completed, average training loss is 0.057160125761292875\n",
            "Testing Acc.: 0.9761000090837478\n",
            "Epoch 114 completed, average training loss is 0.05620987122296356\n",
            "Testing Acc.: 0.9765000075101853\n",
            "Epoch 115 completed, average training loss is 0.05562983187769229\n",
            "Testing Acc.: 0.9757000064849853\n",
            "Epoch 116 completed, average training loss is 0.05592515019505906\n",
            "Testing Acc.: 0.9764000070095062\n",
            "Epoch 117 completed, average training loss is 0.0570281635170492\n",
            "Testing Acc.: 0.9765000081062317\n",
            "Epoch 118 completed, average training loss is 0.05413856237234237\n",
            "Testing Acc.: 0.9777000081539154\n",
            "Epoch 119 completed, average training loss is 0.05686214417917654\n",
            "Testing Acc.: 0.9717000091075897\n",
            "Epoch 120 completed, average training loss is 0.05620003975559181\n",
            "Testing Acc.: 0.9770000076293945\n",
            "Epoch 121 completed, average training loss is 0.05473267464626891\n",
            "Testing Acc.: 0.9752000057697296\n",
            "Epoch 122 completed, average training loss is 0.05574384448234923\n",
            "Testing Acc.: 0.9748000073432922\n",
            "Epoch 123 completed, average training loss is 0.05671244870056398\n",
            "Testing Acc.: 0.975400008559227\n",
            "Epoch 124 completed, average training loss is 0.054598690428538245\n",
            "Testing Acc.: 0.9737000077962875\n",
            "Epoch 125 completed, average training loss is 0.05414423300574223\n",
            "Testing Acc.: 0.9756000053882599\n",
            "Epoch 126 completed, average training loss is 0.05649665622971952\n",
            "Testing Acc.: 0.9781000065803528\n",
            "Epoch 127 completed, average training loss is 0.053812956074252724\n",
            "Testing Acc.: 0.9763000071048736\n",
            "Epoch 128 completed, average training loss is 0.053681667029935244\n",
            "Testing Acc.: 0.9737000066041946\n",
            "Epoch 129 completed, average training loss is 0.05333807064666568\n",
            "Testing Acc.: 0.9778000080585479\n",
            "Epoch 130 completed, average training loss is 0.05459144757750134\n",
            "Testing Acc.: 0.9755000072717667\n",
            "Epoch 131 completed, average training loss is 0.05516722050805887\n",
            "Testing Acc.: 0.9736000061035156\n",
            "Epoch 132 completed, average training loss is 0.053149256501346824\n",
            "Testing Acc.: 0.9738000059127807\n",
            "Epoch 133 completed, average training loss is 0.05514521314956558\n",
            "Testing Acc.: 0.9783000057935715\n",
            "Epoch 134 completed, average training loss is 0.05320382615473742\n",
            "Testing Acc.: 0.9762000072002411\n",
            "Epoch 135 completed, average training loss is 0.0543605894203453\n",
            "Testing Acc.: 0.9739000058174133\n",
            "Epoch 136 completed, average training loss is 0.055072621303843335\n",
            "Testing Acc.: 0.9767000073194504\n",
            "Epoch 137 completed, average training loss is 0.052218716290468974\n",
            "Testing Acc.: 0.9763000077009201\n",
            "Epoch 138 completed, average training loss is 0.051563644938481354\n",
            "Testing Acc.: 0.9763000065088272\n",
            "Epoch 139 completed, average training loss is 0.05422946349484846\n",
            "Testing Acc.: 0.9775000083446502\n",
            "Epoch 140 completed, average training loss is 0.05365044788554466\n",
            "Testing Acc.: 0.9727000069618225\n",
            "Epoch 141 completed, average training loss is 0.05579766288710137\n",
            "Testing Acc.: 0.97710000872612\n",
            "Epoch 142 completed, average training loss is 0.05481022130077084\n",
            "Testing Acc.: 0.9744000059366226\n",
            "Epoch 143 completed, average training loss is 0.0525769073702395\n",
            "Testing Acc.: 0.9766000092029572\n",
            "Epoch 144 completed, average training loss is 0.052752892823773434\n",
            "Testing Acc.: 0.9785000085830688\n",
            "Epoch 145 completed, average training loss is 0.05231557824260866\n",
            "Testing Acc.: 0.975300008058548\n",
            "Epoch 146 completed, average training loss is 0.05153043349389918\n",
            "Testing Acc.: 0.976200008392334\n",
            "Epoch 147 completed, average training loss is 0.051907689036258184\n",
            "Testing Acc.: 0.9758000069856644\n",
            "Epoch 148 completed, average training loss is 0.053996613500445774\n",
            "Testing Acc.: 0.9756000083684921\n",
            "Epoch 149 completed, average training loss is 0.05262281670739564\n",
            "Testing Acc.: 0.9760000073909759\n",
            "Epoch 150 completed, average training loss is 0.051536248483074205\n",
            "Testing Acc.: 0.972900008559227\n",
            "Epoch 151 completed, average training loss is 0.05317108921570859\n",
            "Testing Acc.: 0.9759000098705292\n",
            "Epoch 152 completed, average training loss is 0.052309608963550996\n",
            "Testing Acc.: 0.976700006723404\n",
            "Epoch 153 completed, average training loss is 0.05223305546795018\n",
            "Testing Acc.: 0.9749000066518784\n",
            "Epoch 154 completed, average training loss is 0.05078918136151818\n",
            "Testing Acc.: 0.9767000085115433\n",
            "Epoch 155 completed, average training loss is 0.05154455261110949\n",
            "Testing Acc.: 0.9760000073909759\n",
            "Epoch 156 completed, average training loss is 0.05160944981733337\n",
            "Testing Acc.: 0.9731000065803528\n",
            "Epoch 157 completed, average training loss is 0.05154348740664621\n",
            "Testing Acc.: 0.9759000074863434\n",
            "Epoch 158 completed, average training loss is 0.051423902764605976\n",
            "Testing Acc.: 0.9746000063419342\n",
            "Epoch 159 completed, average training loss is 0.051580821412305036\n",
            "Testing Acc.: 0.9748000055551529\n",
            "Epoch 160 completed, average training loss is 0.05169755593931768\n",
            "Testing Acc.: 0.978600007891655\n",
            "Epoch 161 completed, average training loss is 0.05218890450235146\n",
            "Testing Acc.: 0.9719000053405762\n",
            "Epoch 162 completed, average training loss is 0.050409574915344514\n",
            "Testing Acc.: 0.9781000095605851\n",
            "Epoch 163 completed, average training loss is 0.05123864738619886\n",
            "Testing Acc.: 0.9775000083446502\n",
            "Epoch 164 completed, average training loss is 0.05095295920308369\n",
            "Testing Acc.: 0.9730000078678132\n",
            "Epoch 165 completed, average training loss is 0.051940827790337304\n",
            "Testing Acc.: 0.9781000083684921\n",
            "Epoch 166 completed, average training loss is 0.05169970639050007\n",
            "Testing Acc.: 0.9760000079870224\n",
            "Epoch 167 completed, average training loss is 0.051047108867205676\n",
            "Testing Acc.: 0.9758000081777572\n",
            "Epoch 168 completed, average training loss is 0.0501946395325164\n",
            "Testing Acc.: 0.9755000084638595\n",
            "Epoch 169 completed, average training loss is 0.051311713142786174\n",
            "Testing Acc.: 0.9737000089883804\n",
            "Epoch 170 completed, average training loss is 0.04999574172776192\n",
            "Testing Acc.: 0.9787000089883804\n",
            "Epoch 171 completed, average training loss is 0.050640747544433304\n",
            "Testing Acc.: 0.9765000069141387\n",
            "Epoch 172 completed, average training loss is 0.050590090187033636\n",
            "Testing Acc.: 0.9758000057935715\n",
            "Epoch 173 completed, average training loss is 0.051977422230411324\n",
            "Testing Acc.: 0.9769000071287155\n",
            "Epoch 174 completed, average training loss is 0.052140344294408954\n",
            "Testing Acc.: 0.9787000101804734\n",
            "Epoch 175 completed, average training loss is 0.0509413824309983\n",
            "Testing Acc.: 0.9765000075101853\n",
            "Epoch 176 completed, average training loss is 0.050077395412372425\n",
            "Testing Acc.: 0.9716000086069108\n",
            "Epoch 177 completed, average training loss is 0.04964765708039825\n",
            "Testing Acc.: 0.9747000062465667\n",
            "Epoch 178 completed, average training loss is 0.05252487124525942\n",
            "Testing Acc.: 0.9781000089645385\n",
            "Epoch 179 completed, average training loss is 0.04946967733946318\n",
            "Testing Acc.: 0.9757000088691712\n",
            "Epoch 180 completed, average training loss is 0.05000932351123386\n",
            "Testing Acc.: 0.9762000060081482\n",
            "Epoch 181 completed, average training loss is 0.050540661282138896\n",
            "Testing Acc.: 0.9759000092744827\n",
            "Epoch 182 completed, average training loss is 0.04916398939249727\n",
            "Testing Acc.: 0.9747000080347061\n",
            "Epoch 183 completed, average training loss is 0.04978206457007521\n",
            "Testing Acc.: 0.9744000095129013\n",
            "Epoch 184 completed, average training loss is 0.05014999150337341\n",
            "Testing Acc.: 0.974500008225441\n",
            "Epoch 185 completed, average training loss is 0.050511017443301776\n",
            "Testing Acc.: 0.9749000084400177\n",
            "Epoch 186 completed, average training loss is 0.048444471058319324\n",
            "Testing Acc.: 0.9786000096797943\n",
            "Epoch 187 completed, average training loss is 0.04848071423630851\n",
            "Testing Acc.: 0.976700006723404\n",
            "Epoch 188 completed, average training loss is 0.04867067974836876\n",
            "Testing Acc.: 0.9762000095844269\n",
            "Epoch 189 completed, average training loss is 0.050299473992005614\n",
            "Testing Acc.: 0.9763000059127808\n",
            "Epoch 190 completed, average training loss is 0.05071643373734939\n",
            "Testing Acc.: 0.9744000071287156\n",
            "Epoch 191 completed, average training loss is 0.050535828518526005\n",
            "Testing Acc.: 0.9762000042200089\n",
            "Epoch 192 completed, average training loss is 0.04907691593378938\n",
            "Testing Acc.: 0.9758000057935715\n",
            "Epoch 193 completed, average training loss is 0.04961100613678961\n",
            "Testing Acc.: 0.976500009894371\n",
            "Epoch 194 completed, average training loss is 0.048907793989831895\n",
            "Testing Acc.: 0.9739000070095062\n",
            "Epoch 195 completed, average training loss is 0.04876332227237678\n",
            "Testing Acc.: 0.9777000069618225\n",
            "Epoch 196 completed, average training loss is 0.049010007925874864\n",
            "Testing Acc.: 0.9763000082969665\n",
            "Epoch 197 completed, average training loss is 0.04827246030462751\n",
            "Testing Acc.: 0.9781000101566315\n",
            "Epoch 198 completed, average training loss is 0.04850926204021865\n",
            "Testing Acc.: 0.9731000065803528\n",
            "Epoch 199 completed, average training loss is 0.04900566239763672\n",
            "Testing Acc.: 0.9767000079154968\n",
            "Epoch 200 completed, average training loss is 0.04948541394706505\n",
            "Testing Acc.: 0.9780000060796737\n",
            "Epoch 201 completed, average training loss is 0.15055458384255568\n",
            "Testing Acc.: 0.959100006222725\n",
            "Epoch 202 completed, average training loss is 0.13275766456034035\n",
            "Testing Acc.: 0.9548000037670136\n",
            "Epoch 203 completed, average training loss is 0.1203926125401631\n",
            "Testing Acc.: 0.9596000039577484\n",
            "Epoch 204 completed, average training loss is 0.11604501746827736\n",
            "Testing Acc.: 0.9647000020742417\n",
            "Epoch 205 completed, average training loss is 0.12506712868188818\n",
            "Testing Acc.: 0.9605000042915344\n",
            "Epoch 206 completed, average training loss is 0.1237457254040055\n",
            "Testing Acc.: 0.9577000045776367\n",
            "Epoch 207 completed, average training loss is 0.1246627019563069\n",
            "Testing Acc.: 0.9564000040292739\n",
            "Epoch 208 completed, average training loss is 0.13773967703183493\n",
            "Testing Acc.: 0.9521000039577484\n",
            "Epoch 209 completed, average training loss is 0.13078666416617732\n",
            "Testing Acc.: 0.9541000038385391\n",
            "Epoch 210 completed, average training loss is 0.12773703823952626\n",
            "Testing Acc.: 0.9569000047445297\n",
            "Epoch 211 completed, average training loss is 0.12989078981180985\n",
            "Testing Acc.: 0.958300005197525\n",
            "Epoch 212 completed, average training loss is 0.12863977543544025\n",
            "Testing Acc.: 0.9590000039339066\n",
            "Epoch 213 completed, average training loss is 0.12175927447155117\n",
            "Testing Acc.: 0.9570000046491622\n",
            "Epoch 214 completed, average training loss is 0.12421892914300163\n",
            "Testing Acc.: 0.9577000027894974\n",
            "Epoch 215 completed, average training loss is 0.13576138717432817\n",
            "Testing Acc.: 0.9559000027179718\n",
            "Epoch 216 completed, average training loss is 0.136825997227182\n",
            "Testing Acc.: 0.9598000049591064\n",
            "Epoch 217 completed, average training loss is 0.13464375688539196\n",
            "Testing Acc.: 0.9523000019788742\n",
            "Epoch 218 completed, average training loss is 0.13294847867141169\n",
            "Testing Acc.: 0.9612000072002411\n",
            "Epoch 219 completed, average training loss is 0.12281558954312155\n",
            "Testing Acc.: 0.9579000025987625\n",
            "Epoch 220 completed, average training loss is 0.13058916126533102\n",
            "Testing Acc.: 0.9606000047922134\n",
            "Epoch 221 completed, average training loss is 0.11268409719069798\n",
            "Testing Acc.: 0.9656000036001205\n",
            "Epoch 222 completed, average training loss is 0.11905655089144905\n",
            "Testing Acc.: 0.9639000046253204\n",
            "Epoch 223 completed, average training loss is 0.11554525673078994\n",
            "Testing Acc.: 0.9635000038146972\n",
            "Epoch 224 completed, average training loss is 0.10910974939043323\n",
            "Testing Acc.: 0.9610000044107437\n",
            "Epoch 225 completed, average training loss is 0.10733523752229909\n",
            "Testing Acc.: 0.9650000017881394\n",
            "Epoch 226 completed, average training loss is 0.10885073504410685\n",
            "Testing Acc.: 0.9620000052452088\n",
            "Epoch 227 completed, average training loss is 0.10330408943196137\n",
            "Testing Acc.: 0.9674000066518783\n",
            "Epoch 228 completed, average training loss is 0.1067349770044287\n",
            "Testing Acc.: 0.9644000035524368\n",
            "Epoch 229 completed, average training loss is 0.11595626117351154\n",
            "Testing Acc.: 0.9583000028133393\n",
            "Epoch 230 completed, average training loss is 0.1244748218699048\n",
            "Testing Acc.: 0.9592000013589859\n",
            "Epoch 231 completed, average training loss is 0.12839724108421555\n",
            "Testing Acc.: 0.9614000034332275\n",
            "Epoch 232 completed, average training loss is 0.12351537213660777\n",
            "Testing Acc.: 0.9610000026226043\n",
            "Epoch 233 completed, average training loss is 0.12602062976453454\n",
            "Testing Acc.: 0.9596000045537949\n",
            "Epoch 234 completed, average training loss is 0.11783992337839057\n",
            "Testing Acc.: 0.960600004196167\n",
            "Epoch 235 completed, average training loss is 0.11816962134869148\n",
            "Testing Acc.: 0.9611000007390976\n",
            "Epoch 236 completed, average training loss is 0.1207431244260321\n",
            "Testing Acc.: 0.95980000436306\n",
            "Epoch 237 completed, average training loss is 0.11320071814426531\n",
            "Testing Acc.: 0.9632000029087067\n",
            "Epoch 238 completed, average training loss is 0.10717752198999127\n",
            "Testing Acc.: 0.9606000047922134\n",
            "Epoch 239 completed, average training loss is 0.10904486249977102\n",
            "Testing Acc.: 0.9607000052928925\n",
            "Epoch 240 completed, average training loss is 0.11415609352911513\n",
            "Testing Acc.: 0.9616000074148178\n",
            "Epoch 241 completed, average training loss is 0.11786389553919435\n",
            "Testing Acc.: 0.9597000050544738\n",
            "Epoch 242 completed, average training loss is 0.11202422191544126\n",
            "Testing Acc.: 0.9592000049352646\n",
            "Epoch 243 completed, average training loss is 0.12005156420792143\n",
            "Testing Acc.: 0.9589000028371811\n",
            "Epoch 244 completed, average training loss is 0.11061468565526109\n",
            "Testing Acc.: 0.9615000033378601\n",
            "Epoch 245 completed, average training loss is 0.10865190836290518\n",
            "Testing Acc.: 0.9602000045776368\n",
            "Epoch 246 completed, average training loss is 0.11712816403247416\n",
            "Testing Acc.: 0.9585000056028367\n",
            "Epoch 247 completed, average training loss is 0.12374693867750466\n",
            "Testing Acc.: 0.9593000012636185\n",
            "Epoch 248 completed, average training loss is 0.12492905415284138\n",
            "Testing Acc.: 0.9618000030517578\n",
            "Epoch 249 completed, average training loss is 0.11439574857242406\n",
            "Testing Acc.: 0.9617000073194504\n",
            "Epoch 250 completed, average training loss is 0.11098363909249505\n",
            "Testing Acc.: 0.9661000055074692\n",
            "Epoch 251 completed, average training loss is 0.12134666445975502\n",
            "Testing Acc.: 0.9527000027894974\n",
            "Epoch 252 completed, average training loss is 0.14505173191428183\n",
            "Testing Acc.: 0.9561000025272369\n",
            "Epoch 253 completed, average training loss is 0.13478273400726418\n",
            "Testing Acc.: 0.9551000046730042\n",
            "Epoch 254 completed, average training loss is 0.11927535759285092\n",
            "Testing Acc.: 0.963600006699562\n",
            "Epoch 255 completed, average training loss is 0.11862153514909247\n",
            "Testing Acc.: 0.9619000053405762\n",
            "Epoch 256 completed, average training loss is 0.12188906751262645\n",
            "Testing Acc.: 0.9618000030517578\n",
            "Epoch 257 completed, average training loss is 0.11680940061497191\n",
            "Testing Acc.: 0.9580000030994416\n",
            "Epoch 258 completed, average training loss is 0.12452742942608892\n",
            "Testing Acc.: 0.9558000016212463\n",
            "Epoch 259 completed, average training loss is 0.11939175992272794\n",
            "Testing Acc.: 0.9611000061035156\n",
            "Epoch 260 completed, average training loss is 0.11906683512342472\n",
            "Testing Acc.: 0.9595000046491623\n",
            "Epoch 261 completed, average training loss is 0.12435043667753537\n",
            "Testing Acc.: 0.9594000053405761\n",
            "Epoch 262 completed, average training loss is 0.11260052280810973\n",
            "Testing Acc.: 0.9651000016927719\n",
            "Epoch 263 completed, average training loss is 0.1037478277583917\n",
            "Testing Acc.: 0.9646000057458878\n",
            "Epoch 264 completed, average training loss is 0.11927034014835954\n",
            "Testing Acc.: 0.9583000063896179\n",
            "Epoch 265 completed, average training loss is 0.12133494776673615\n",
            "Testing Acc.: 0.9588000059127808\n",
            "Epoch 266 completed, average training loss is 0.12630720398078363\n",
            "Testing Acc.: 0.9589000034332276\n",
            "Epoch 267 completed, average training loss is 0.1236327357745419\n",
            "Testing Acc.: 0.953800003528595\n",
            "Epoch 268 completed, average training loss is 0.13985171221817533\n",
            "Testing Acc.: 0.9502000051736832\n",
            "Epoch 269 completed, average training loss is 0.15094869738444686\n",
            "Testing Acc.: 0.9516000056266785\n",
            "Epoch 270 completed, average training loss is 0.14693104164364437\n",
            "Testing Acc.: 0.9504000008106231\n",
            "Epoch 271 completed, average training loss is 0.14950264785749218\n",
            "Testing Acc.: 0.9509000009298325\n",
            "Epoch 272 completed, average training loss is 0.13571644799162944\n",
            "Testing Acc.: 0.9558000040054321\n",
            "Epoch 273 completed, average training loss is 0.1396122426415483\n",
            "Testing Acc.: 0.9546000039577485\n",
            "Epoch 274 completed, average training loss is 0.13811079089219372\n",
            "Testing Acc.: 0.9569000053405762\n",
            "Epoch 275 completed, average training loss is 0.15400330799010892\n",
            "Testing Acc.: 0.947200003862381\n",
            "Epoch 276 completed, average training loss is 0.16422669452304642\n",
            "Testing Acc.: 0.9468000054359436\n",
            "Epoch 277 completed, average training loss is 0.1581266343500465\n",
            "Testing Acc.: 0.9454000014066696\n",
            "Epoch 278 completed, average training loss is 0.16369853378894428\n",
            "Testing Acc.: 0.9444000053405762\n",
            "Epoch 279 completed, average training loss is 0.16142467641582092\n",
            "Testing Acc.: 0.9474000036716461\n",
            "Epoch 280 completed, average training loss is 0.14798856856922307\n",
            "Testing Acc.: 0.9519000023603439\n",
            "Epoch 281 completed, average training loss is 0.14714627329880992\n",
            "Testing Acc.: 0.9463000047206879\n",
            "Epoch 282 completed, average training loss is 0.16227411655088267\n",
            "Testing Acc.: 0.9403000020980835\n",
            "Epoch 283 completed, average training loss is 0.17461595365777613\n",
            "Testing Acc.: 0.938700001835823\n",
            "Epoch 284 completed, average training loss is 0.1526128630278011\n",
            "Testing Acc.: 0.9520000028610229\n",
            "Epoch 285 completed, average training loss is 0.13211521570260326\n",
            "Testing Acc.: 0.9552000081539154\n",
            "Epoch 286 completed, average training loss is 0.1431450828226904\n",
            "Testing Acc.: 0.9476000028848648\n",
            "Epoch 287 completed, average training loss is 0.14869822514553865\n",
            "Testing Acc.: 0.9527000057697296\n",
            "Epoch 288 completed, average training loss is 0.14580043534748255\n",
            "Testing Acc.: 0.9519000035524369\n",
            "Epoch 289 completed, average training loss is 0.14726013123989104\n",
            "Testing Acc.: 0.9457000041007996\n",
            "Epoch 290 completed, average training loss is 0.15534541644776861\n",
            "Testing Acc.: 0.9464000052213669\n",
            "Epoch 291 completed, average training loss is 0.14178251646148662\n",
            "Testing Acc.: 0.9481000047922135\n",
            "Epoch 292 completed, average training loss is 0.13898990172582368\n",
            "Testing Acc.: 0.9569000035524369\n",
            "Epoch 293 completed, average training loss is 0.13610329547586542\n",
            "Testing Acc.: 0.9553000038862228\n",
            "Epoch 294 completed, average training loss is 0.1335791777788351\n",
            "Testing Acc.: 0.9487000054121018\n",
            "Epoch 295 completed, average training loss is 0.139872918886443\n",
            "Testing Acc.: 0.9582000035047531\n",
            "Epoch 296 completed, average training loss is 0.13336761536697547\n",
            "Testing Acc.: 0.9518000030517578\n",
            "Epoch 297 completed, average training loss is 0.1352185583456109\n",
            "Testing Acc.: 0.954600002169609\n",
            "Epoch 298 completed, average training loss is 0.12724874286601942\n",
            "Testing Acc.: 0.9572000050544739\n",
            "Epoch 299 completed, average training loss is 0.12229961133872469\n",
            "Testing Acc.: 0.9591000044345855\n",
            "Epoch 300 completed, average training loss is 0.11732959234155714\n",
            "Testing Acc.: 0.9601000034809113\n",
            "Epoch 301 completed, average training loss is 0.12646753186360002\n",
            "Testing Acc.: 0.9492000043392181\n",
            "Epoch 302 completed, average training loss is 0.14040990241803228\n",
            "Testing Acc.: 0.9526000028848648\n",
            "Epoch 303 completed, average training loss is 0.12155923483582834\n",
            "Testing Acc.: 0.9588000053167343\n",
            "Epoch 304 completed, average training loss is 0.12227280518971384\n",
            "Testing Acc.: 0.9571000051498413\n",
            "Epoch 305 completed, average training loss is 0.12948506605500976\n",
            "Testing Acc.: 0.961000006198883\n",
            "Epoch 306 completed, average training loss is 0.13047817963796357\n",
            "Testing Acc.: 0.9518000030517578\n",
            "Epoch 307 completed, average training loss is 0.1351770412735641\n",
            "Testing Acc.: 0.9555000019073486\n",
            "Epoch 308 completed, average training loss is 0.1240570246707648\n",
            "Testing Acc.: 0.958200004696846\n",
            "Epoch 309 completed, average training loss is 0.12421188310720027\n",
            "Testing Acc.: 0.9533000057935714\n",
            "Epoch 310 completed, average training loss is 0.12070113745207588\n",
            "Testing Acc.: 0.9578000062704086\n",
            "Epoch 311 completed, average training loss is 0.12776948539850613\n",
            "Testing Acc.: 0.9557000035047531\n",
            "Epoch 312 completed, average training loss is 0.12314570632452766\n",
            "Testing Acc.: 0.9605000030994415\n",
            "Epoch 313 completed, average training loss is 0.11456106237446269\n",
            "Testing Acc.: 0.9609000051021576\n",
            "Epoch 314 completed, average training loss is 0.11657187878154218\n",
            "Testing Acc.: 0.9598000055551529\n",
            "Epoch 315 completed, average training loss is 0.12271488652254145\n",
            "Testing Acc.: 0.9618000054359436\n",
            "Epoch 316 completed, average training loss is 0.11843509596462051\n",
            "Testing Acc.: 0.9625000035762787\n",
            "Epoch 317 completed, average training loss is 0.11609184411820024\n",
            "Testing Acc.: 0.9619000035524369\n",
            "Epoch 318 completed, average training loss is 0.11525118513032793\n",
            "Testing Acc.: 0.9620999997854233\n",
            "Epoch 319 completed, average training loss is 0.12661334173753858\n",
            "Testing Acc.: 0.9640000039339065\n",
            "Epoch 320 completed, average training loss is 0.10627029729386171\n",
            "Testing Acc.: 0.9679000043869018\n",
            "Epoch 321 completed, average training loss is 0.106823956410711\n",
            "Testing Acc.: 0.9619000041484833\n",
            "Epoch 322 completed, average training loss is 0.10634870441009601\n",
            "Testing Acc.: 0.9641000074148178\n",
            "Epoch 323 completed, average training loss is 0.10748657687411954\n",
            "Testing Acc.: 0.9642000049352646\n",
            "Epoch 324 completed, average training loss is 0.11626660500653088\n",
            "Testing Acc.: 0.9605000025033951\n",
            "Epoch 325 completed, average training loss is 0.1349257362804686\n",
            "Testing Acc.: 0.9595000046491623\n",
            "Epoch 326 completed, average training loss is 0.1157917550796022\n",
            "Testing Acc.: 0.9602000051736832\n",
            "Epoch 327 completed, average training loss is 0.1073115206634005\n",
            "Testing Acc.: 0.9613000017404556\n",
            "Epoch 328 completed, average training loss is 0.11539961164817214\n",
            "Testing Acc.: 0.9642000019550323\n",
            "Epoch 329 completed, average training loss is 0.106924748228242\n",
            "Testing Acc.: 0.9655000019073486\n",
            "Epoch 330 completed, average training loss is 0.10941838154103607\n",
            "Testing Acc.: 0.9643000048398972\n",
            "Epoch 331 completed, average training loss is 0.10925892663188279\n",
            "Testing Acc.: 0.9618000066280366\n",
            "Epoch 332 completed, average training loss is 0.12225121995434166\n",
            "Testing Acc.: 0.9608000040054321\n",
            "Epoch 333 completed, average training loss is 0.13460455421358347\n",
            "Testing Acc.: 0.9434000027179718\n",
            "Epoch 334 completed, average training loss is 0.14914682388305664\n",
            "Testing Acc.: 0.9599000042676926\n",
            "Epoch 335 completed, average training loss is 0.1228507862612605\n",
            "Testing Acc.: 0.9543000036478042\n",
            "Epoch 336 completed, average training loss is 0.11323543493635953\n",
            "Testing Acc.: 0.9647000044584274\n",
            "Epoch 337 completed, average training loss is 0.12034038486269613\n",
            "Testing Acc.: 0.9612000048160553\n",
            "Epoch 338 completed, average training loss is 0.12467896368354559\n",
            "Testing Acc.: 0.9609000051021576\n",
            "Epoch 339 completed, average training loss is 0.1250261409704884\n",
            "Testing Acc.: 0.9567000055313111\n",
            "Epoch 340 completed, average training loss is 0.13063131126575173\n",
            "Testing Acc.: 0.956200003027916\n",
            "Epoch 341 completed, average training loss is 0.12191025572518507\n",
            "Testing Acc.: 0.9589000028371811\n",
            "Epoch 342 completed, average training loss is 0.13514363426094253\n",
            "Testing Acc.: 0.9512000054121017\n",
            "Epoch 343 completed, average training loss is 0.1401599589549005\n",
            "Testing Acc.: 0.9516000032424927\n",
            "Epoch 344 completed, average training loss is 0.13229106523717443\n",
            "Testing Acc.: 0.9555000060796738\n",
            "Epoch 345 completed, average training loss is 0.12461043576554706\n",
            "Testing Acc.: 0.9598000055551529\n",
            "Epoch 346 completed, average training loss is 0.11079409254249185\n",
            "Testing Acc.: 0.9618000048398971\n",
            "Epoch 347 completed, average training loss is 0.11579793775143722\n",
            "Testing Acc.: 0.9639000052213669\n",
            "Epoch 348 completed, average training loss is 0.11894632232065003\n",
            "Testing Acc.: 0.9629000043869018\n",
            "Epoch 349 completed, average training loss is 0.11570935847548147\n",
            "Testing Acc.: 0.9627000027894974\n",
            "Epoch 350 completed, average training loss is 0.11642411516048014\n",
            "Testing Acc.: 0.963400005698204\n",
            "Epoch 351 completed, average training loss is 0.11953033768416693\n",
            "Testing Acc.: 0.9573000019788742\n",
            "Epoch 352 completed, average training loss is 0.12682491642733415\n",
            "Testing Acc.: 0.9587000030279159\n",
            "Epoch 353 completed, average training loss is 0.11986645857493082\n",
            "Testing Acc.: 0.9597000056505203\n",
            "Epoch 354 completed, average training loss is 0.1193947398973008\n",
            "Testing Acc.: 0.9608000051975251\n",
            "Epoch 355 completed, average training loss is 0.12160987546977897\n",
            "Testing Acc.: 0.9642000049352646\n",
            "Epoch 356 completed, average training loss is 0.11371074476279318\n",
            "Testing Acc.: 0.9647000056505203\n",
            "Epoch 357 completed, average training loss is 0.10651188030062864\n",
            "Testing Acc.: 0.9612000054121017\n",
            "Epoch 358 completed, average training loss is 0.1077638293399165\n",
            "Testing Acc.: 0.9664000052213669\n",
            "Epoch 359 completed, average training loss is 0.11082200119271875\n",
            "Testing Acc.: 0.9605000036954879\n",
            "Epoch 360 completed, average training loss is 0.11306460565887391\n",
            "Testing Acc.: 0.9626000064611435\n",
            "Epoch 361 completed, average training loss is 0.10306055034821232\n",
            "Testing Acc.: 0.9651000034809113\n",
            "Epoch 362 completed, average training loss is 0.10398270930939664\n",
            "Testing Acc.: 0.964400007724762\n",
            "Epoch 363 completed, average training loss is 0.11253063782118261\n",
            "Testing Acc.: 0.9646000039577484\n",
            "Epoch 364 completed, average training loss is 0.10554333811315397\n",
            "Testing Acc.: 0.9625000041723252\n",
            "Epoch 365 completed, average training loss is 0.11058095055942734\n",
            "Testing Acc.: 0.9643000018596649\n",
            "Epoch 366 completed, average training loss is 0.12635497622502348\n",
            "Testing Acc.: 0.9546000051498413\n",
            "Epoch 367 completed, average training loss is 0.1541228055022657\n",
            "Testing Acc.: 0.9528000038862229\n",
            "Epoch 368 completed, average training loss is 0.11843142570306857\n",
            "Testing Acc.: 0.9634000045061112\n",
            "Epoch 369 completed, average training loss is 0.10772771469006935\n",
            "Testing Acc.: 0.9658000057935715\n",
            "Epoch 370 completed, average training loss is 0.10550264243036508\n",
            "Testing Acc.: 0.9667000043392181\n",
            "Epoch 371 completed, average training loss is 0.11206002134208878\n",
            "Testing Acc.: 0.9627000027894974\n",
            "Epoch 372 completed, average training loss is 0.11645102694941063\n",
            "Testing Acc.: 0.9646000039577484\n",
            "Epoch 373 completed, average training loss is 0.11840139759083589\n",
            "Testing Acc.: 0.9601000040769577\n",
            "Epoch 374 completed, average training loss is 0.13106395727644363\n",
            "Testing Acc.: 0.9592000061273575\n",
            "Epoch 375 completed, average training loss is 0.12085894044023007\n",
            "Testing Acc.: 0.9597000020742417\n",
            "Epoch 376 completed, average training loss is 0.13952538741131623\n",
            "Testing Acc.: 0.9493000024557113\n",
            "Epoch 377 completed, average training loss is 0.15520893656027815\n",
            "Testing Acc.: 0.9482000029087067\n",
            "Epoch 378 completed, average training loss is 0.1659167222833882\n",
            "Testing Acc.: 0.9501000022888184\n",
            "Epoch 379 completed, average training loss is 0.14085456661880016\n",
            "Testing Acc.: 0.956200003027916\n",
            "Epoch 380 completed, average training loss is 0.12479898616982003\n",
            "Testing Acc.: 0.954200005531311\n",
            "Epoch 381 completed, average training loss is 0.13870407007945082\n",
            "Testing Acc.: 0.9542000049352646\n",
            "Epoch 382 completed, average training loss is 0.13225895426856973\n",
            "Testing Acc.: 0.9583000040054321\n",
            "Epoch 383 completed, average training loss is 0.13068594895768912\n",
            "Testing Acc.: 0.9609000074863434\n",
            "Epoch 384 completed, average training loss is 0.11866591957087318\n",
            "Testing Acc.: 0.9605000078678131\n",
            "Epoch 385 completed, average training loss is 0.11667743630396823\n",
            "Testing Acc.: 0.9597000062465668\n",
            "Epoch 386 completed, average training loss is 0.11448216540428499\n",
            "Testing Acc.: 0.959500002861023\n",
            "Epoch 387 completed, average training loss is 0.11483481604295473\n",
            "Testing Acc.: 0.9641000056266784\n",
            "Epoch 388 completed, average training loss is 0.10942504858753334\n",
            "Testing Acc.: 0.9651000028848649\n",
            "Epoch 389 completed, average training loss is 0.1101216658949852\n",
            "Testing Acc.: 0.9657000035047532\n",
            "Epoch 390 completed, average training loss is 0.10843386964562039\n",
            "Testing Acc.: 0.9615000051259994\n",
            "Epoch 391 completed, average training loss is 0.10987135466343413\n",
            "Testing Acc.: 0.9637000036239624\n",
            "Epoch 392 completed, average training loss is 0.11079426545339326\n",
            "Testing Acc.: 0.9629000020027161\n",
            "Epoch 393 completed, average training loss is 0.11183263215081145\n",
            "Testing Acc.: 0.9625000029802322\n",
            "Epoch 394 completed, average training loss is 0.11643101938379308\n",
            "Testing Acc.: 0.959000004529953\n",
            "Epoch 395 completed, average training loss is 0.12107312838857373\n",
            "Testing Acc.: 0.96030000269413\n",
            "Epoch 396 completed, average training loss is 0.11564329860576739\n",
            "Testing Acc.: 0.960600004196167\n",
            "Epoch 397 completed, average training loss is 0.11876219486817717\n",
            "Testing Acc.: 0.958100003004074\n",
            "Epoch 398 completed, average training loss is 0.12432098801247776\n",
            "Testing Acc.: 0.9560000056028366\n",
            "Epoch 399 completed, average training loss is 0.13074081796997536\n",
            "Testing Acc.: 0.9561000037193298\n",
            "Epoch 400 completed, average training loss is 0.12816120934051772\n",
            "Testing Acc.: 0.9600000047683716\n",
            "Epoch 401 completed, average training loss is 7.518473351796468\n",
            "Testing Acc.: 0.9537000054121018\n",
            "Epoch 402 completed, average training loss is 1.5322364168365796\n",
            "Testing Acc.: 0.9517000013589859\n",
            "Epoch 403 completed, average training loss is 0.8387712829311689\n",
            "Testing Acc.: 0.9465000057220458\n",
            "Epoch 404 completed, average training loss is 0.49930777207016946\n",
            "Testing Acc.: 0.9470000040531158\n",
            "Epoch 405 completed, average training loss is 0.27341260412087043\n",
            "Testing Acc.: 0.944700003862381\n",
            "Epoch 406 completed, average training loss is 0.2005022194981575\n",
            "Testing Acc.: 0.9461000031232834\n",
            "Epoch 407 completed, average training loss is 0.1724805180604259\n",
            "Testing Acc.: 0.9456000059843064\n",
            "Epoch 408 completed, average training loss is 0.167788808538268\n",
            "Testing Acc.: 0.9467000061273575\n",
            "Epoch 409 completed, average training loss is 0.1570420311111957\n",
            "Testing Acc.: 0.9458000063896179\n",
            "Epoch 410 completed, average training loss is 0.1540991544847687\n",
            "Testing Acc.: 0.9458000057935715\n",
            "Epoch 411 completed, average training loss is 0.153228899029394\n",
            "Testing Acc.: 0.9473000043630599\n",
            "Epoch 412 completed, average training loss is 0.1843023184562723\n",
            "Testing Acc.: 0.9495000034570694\n",
            "Epoch 413 completed, average training loss is 0.16204715804507336\n",
            "Testing Acc.: 0.9487000066041946\n",
            "Epoch 414 completed, average training loss is 0.20028795716663203\n",
            "Testing Acc.: 0.9482000041007995\n",
            "Epoch 415 completed, average training loss is 0.1980042855689923\n",
            "Testing Acc.: 0.9473000037670135\n",
            "Epoch 416 completed, average training loss is 0.16570065191636482\n",
            "Testing Acc.: 0.9485000044107437\n",
            "Epoch 417 completed, average training loss is 0.1566626884167393\n",
            "Testing Acc.: 0.9473000037670135\n",
            "Epoch 418 completed, average training loss is 0.14896018261089922\n",
            "Testing Acc.: 0.9494000029563904\n",
            "Epoch 419 completed, average training loss is 0.15200146245149274\n",
            "Testing Acc.: 0.9478000044822693\n",
            "Epoch 420 completed, average training loss is 0.1619578313144545\n",
            "Testing Acc.: 0.9477000045776367\n",
            "Epoch 421 completed, average training loss is 0.14623617984354495\n",
            "Testing Acc.: 0.9473000031709671\n",
            "Epoch 422 completed, average training loss is 0.1474371424286316\n",
            "Testing Acc.: 0.9470000022649765\n",
            "Epoch 423 completed, average training loss is 0.15745312571525574\n",
            "Testing Acc.: 0.9491000032424927\n",
            "Epoch 424 completed, average training loss is 0.15995479518237213\n",
            "Testing Acc.: 0.9494000029563904\n",
            "Epoch 425 completed, average training loss is 0.14475491081674893\n",
            "Testing Acc.: 0.9497000026702881\n",
            "Epoch 426 completed, average training loss is 0.16955632088085015\n",
            "Testing Acc.: 0.94950000166893\n",
            "Epoch 427 completed, average training loss is 0.14353428109548985\n",
            "Testing Acc.: 0.9502000027894973\n",
            "Epoch 428 completed, average training loss is 0.14889959200595815\n",
            "Testing Acc.: 0.9503000032901764\n",
            "Epoch 429 completed, average training loss is 0.16370880981286368\n",
            "Testing Acc.: 0.9496000045537949\n",
            "Epoch 430 completed, average training loss is 0.14923819563972454\n",
            "Testing Acc.: 0.9485000032186508\n",
            "Epoch 431 completed, average training loss is 0.14116380384812752\n",
            "Testing Acc.: 0.9492000031471253\n",
            "Epoch 432 completed, average training loss is 0.15323903169172506\n",
            "Testing Acc.: 0.9479000049829484\n",
            "Epoch 433 completed, average training loss is 0.18693347841501237\n",
            "Testing Acc.: 0.9481000024080276\n",
            "Epoch 434 completed, average training loss is 0.15571250054364402\n",
            "Testing Acc.: 0.9498000037670136\n",
            "Epoch 435 completed, average training loss is 0.1413600847342362\n",
            "Testing Acc.: 0.9489000034332276\n",
            "Epoch 436 completed, average training loss is 0.14097828087086478\n",
            "Testing Acc.: 0.9501000016927719\n",
            "Epoch 437 completed, average training loss is 0.14206749815493822\n",
            "Testing Acc.: 0.951100001335144\n",
            "Epoch 438 completed, average training loss is 0.14283335184678436\n",
            "Testing Acc.: 0.9517000025510788\n",
            "Epoch 439 completed, average training loss is 0.15231317867835362\n",
            "Testing Acc.: 0.9468000054359436\n",
            "Epoch 440 completed, average training loss is 0.16543217501292626\n",
            "Testing Acc.: 0.950600004196167\n",
            "Epoch 441 completed, average training loss is 0.14357112371983627\n",
            "Testing Acc.: 0.949500002861023\n",
            "Epoch 442 completed, average training loss is 0.14061806300344568\n",
            "Testing Acc.: 0.9491000026464462\n",
            "Epoch 443 completed, average training loss is 0.13852079691675803\n",
            "Testing Acc.: 0.9498000019788742\n",
            "Epoch 444 completed, average training loss is 0.13733871827212474\n",
            "Testing Acc.: 0.95\n",
            "Epoch 445 completed, average training loss is 0.13676704094279557\n",
            "Testing Acc.: 0.9508000034093856\n",
            "Epoch 446 completed, average training loss is 0.13717080787445107\n",
            "Testing Acc.: 0.9491000020503998\n",
            "Epoch 447 completed, average training loss is 0.14343255657392243\n",
            "Testing Acc.: 0.9502000033855438\n",
            "Epoch 448 completed, average training loss is 0.15609485214576124\n",
            "Testing Acc.: 0.9490000021457672\n",
            "Epoch 449 completed, average training loss is 0.1563550377637148\n",
            "Testing Acc.: 0.9504000025987626\n",
            "Epoch 450 completed, average training loss is 0.13661294971903165\n",
            "Testing Acc.: 0.9510000020265579\n",
            "Epoch 451 completed, average training loss is 0.15378418925528725\n",
            "Testing Acc.: 0.9510000056028366\n",
            "Epoch 452 completed, average training loss is 0.1957819755996267\n",
            "Testing Acc.: 0.9499000024795532\n",
            "Epoch 453 completed, average training loss is 0.15382056372861067\n",
            "Testing Acc.: 0.9511000025272369\n",
            "Epoch 454 completed, average training loss is 0.14497809423754612\n",
            "Testing Acc.: 0.950000005364418\n",
            "Epoch 455 completed, average training loss is 0.1476770772598684\n",
            "Testing Acc.: 0.9508000028133392\n",
            "Epoch 456 completed, average training loss is 0.14404957566410304\n",
            "Testing Acc.: 0.9503000020980835\n",
            "Epoch 457 completed, average training loss is 0.17095210252950588\n",
            "Testing Acc.: 0.9518000036478043\n",
            "Epoch 458 completed, average training loss is 0.16481605069711805\n",
            "Testing Acc.: 0.9516000002622604\n",
            "Epoch 459 completed, average training loss is 0.14605656562373043\n",
            "Testing Acc.: 0.9501000046730042\n",
            "Epoch 460 completed, average training loss is 0.15528515701182186\n",
            "Testing Acc.: 0.952200002670288\n",
            "Epoch 461 completed, average training loss is 0.14394693613052367\n",
            "Testing Acc.: 0.9503000020980835\n",
            "Epoch 462 completed, average training loss is 0.14846596419811248\n",
            "Testing Acc.: 0.9495000034570694\n",
            "Epoch 463 completed, average training loss is 0.1365089117611448\n",
            "Testing Acc.: 0.9503000015020371\n",
            "Epoch 464 completed, average training loss is 0.14477969142297903\n",
            "Testing Acc.: 0.9513000029325486\n",
            "Epoch 465 completed, average training loss is 0.13364093836707375\n",
            "Testing Acc.: 0.9517000019550323\n",
            "Epoch 466 completed, average training loss is 0.1330882999332001\n",
            "Testing Acc.: 0.9508000028133392\n",
            "Epoch 467 completed, average training loss is 0.1362890924575428\n",
            "Testing Acc.: 0.9510000026226044\n",
            "Epoch 468 completed, average training loss is 0.14329108221145967\n",
            "Testing Acc.: 0.9476000016927719\n",
            "Epoch 469 completed, average training loss is 0.15498354299614828\n",
            "Testing Acc.: 0.9510000032186509\n",
            "Epoch 470 completed, average training loss is 0.13536861198643843\n",
            "Testing Acc.: 0.9502000027894973\n",
            "Epoch 471 completed, average training loss is 0.13493499711776774\n",
            "Testing Acc.: 0.9509000045061111\n",
            "Epoch 472 completed, average training loss is 0.14455975362410148\n",
            "Testing Acc.: 0.9505000030994415\n",
            "Epoch 473 completed, average training loss is 0.13710846612850824\n",
            "Testing Acc.: 0.9509000021219254\n",
            "Epoch 474 completed, average training loss is 0.13566031341440976\n",
            "Testing Acc.: 0.9501000028848648\n",
            "Epoch 475 completed, average training loss is 0.1985625168060263\n",
            "Testing Acc.: 0.9507000035047531\n",
            "Epoch 476 completed, average training loss is 0.18425727400307854\n",
            "Testing Acc.: 0.9495000046491623\n",
            "Epoch 477 completed, average training loss is 0.15928762516006828\n",
            "Testing Acc.: 0.9494000023603439\n",
            "Epoch 478 completed, average training loss is 0.15654974680393935\n",
            "Testing Acc.: 0.9523000025749206\n",
            "Epoch 479 completed, average training loss is 0.1346408790629357\n",
            "Testing Acc.: 0.9516000020503997\n",
            "Epoch 480 completed, average training loss is 0.1362696082269152\n",
            "Testing Acc.: 0.9519000029563904\n",
            "Epoch 481 completed, average training loss is 0.1330167688895017\n",
            "Testing Acc.: 0.9511000025272369\n",
            "Epoch 482 completed, average training loss is 0.13369373006746174\n",
            "Testing Acc.: 0.951100001335144\n",
            "Epoch 483 completed, average training loss is 0.13946712508797646\n",
            "Testing Acc.: 0.951300003528595\n",
            "Epoch 484 completed, average training loss is 0.13932904096320273\n",
            "Testing Acc.: 0.9511000007390976\n",
            "Epoch 485 completed, average training loss is 0.14584983935890097\n",
            "Testing Acc.: 0.9514000040292739\n",
            "Epoch 486 completed, average training loss is 0.1654119519330561\n",
            "Testing Acc.: 0.9488000053167344\n",
            "Epoch 487 completed, average training loss is 0.15142613179360828\n",
            "Testing Acc.: 0.9505000036954879\n",
            "Epoch 488 completed, average training loss is 0.13377112624545892\n",
            "Testing Acc.: 0.9508000034093856\n",
            "Epoch 489 completed, average training loss is 0.13250158524606376\n",
            "Testing Acc.: 0.9510000032186509\n",
            "Epoch 490 completed, average training loss is 0.1439366075831155\n",
            "Testing Acc.: 0.9516000062227249\n",
            "Epoch 491 completed, average training loss is 0.14556937403356035\n",
            "Testing Acc.: 0.950400003194809\n",
            "Epoch 492 completed, average training loss is 0.14984351156279443\n",
            "Testing Acc.: 0.9498000001907348\n",
            "Epoch 493 completed, average training loss is 0.13368215582023063\n",
            "Testing Acc.: 0.9502000027894973\n",
            "Epoch 494 completed, average training loss is 0.13013972246088087\n",
            "Testing Acc.: 0.9505000025033951\n",
            "Epoch 495 completed, average training loss is 0.13935872811824082\n",
            "Testing Acc.: 0.9519000047445297\n",
            "Epoch 496 completed, average training loss is 0.16614068994298578\n",
            "Testing Acc.: 0.9524000024795533\n",
            "Epoch 497 completed, average training loss is 0.13418633179118236\n",
            "Testing Acc.: 0.9513000041246414\n",
            "Epoch 498 completed, average training loss is 0.13158659300146003\n",
            "Testing Acc.: 0.9512000036239624\n",
            "Epoch 499 completed, average training loss is 0.12896200615912676\n",
            "Testing Acc.: 0.9512000054121017\n",
            "Epoch 500 completed, average training loss is 0.16204535430297257\n",
            "Testing Acc.: 0.9523000019788742\n",
            "Epoch 501 completed, average training loss is 0.15751379949972033\n",
            "Testing Acc.: 0.9497000002861022\n",
            "Epoch 502 completed, average training loss is 0.13255122017115353\n",
            "Testing Acc.: 0.9517000031471252\n",
            "Epoch 503 completed, average training loss is 0.15395532669499518\n",
            "Testing Acc.: 0.9509000045061111\n",
            "Epoch 504 completed, average training loss is 0.14746834268793463\n",
            "Testing Acc.: 0.9503000038862228\n",
            "Epoch 505 completed, average training loss is 0.1314264832933744\n",
            "Testing Acc.: 0.9514000028371811\n",
            "Epoch 506 completed, average training loss is 0.1294881947680066\n",
            "Testing Acc.: 0.9511000043153763\n",
            "Epoch 507 completed, average training loss is 0.13912293182685972\n",
            "Testing Acc.: 0.9516000056266785\n",
            "Epoch 508 completed, average training loss is 0.16145774916435282\n",
            "Testing Acc.: 0.9514000046253205\n",
            "Epoch 509 completed, average training loss is 0.15259105745702983\n",
            "Testing Acc.: 0.9521000027656555\n",
            "Epoch 510 completed, average training loss is 0.14582761288930973\n",
            "Testing Acc.: 0.9507000035047531\n",
            "Epoch 511 completed, average training loss is 0.1541425721657773\n",
            "Testing Acc.: 0.9514000028371811\n",
            "Epoch 512 completed, average training loss is 0.14325243706814944\n",
            "Testing Acc.: 0.9524000024795533\n",
            "Epoch 513 completed, average training loss is 0.13037212194874884\n",
            "Testing Acc.: 0.9513000011444092\n",
            "Epoch 514 completed, average training loss is 0.12944782041323682\n",
            "Testing Acc.: 0.9504000037908554\n",
            "Epoch 515 completed, average training loss is 0.1458692828193307\n",
            "Testing Acc.: 0.952100003361702\n",
            "Epoch 516 completed, average training loss is 0.15852332492669424\n",
            "Testing Acc.: 0.952200002670288\n",
            "Epoch 517 completed, average training loss is 0.15454351862271626\n",
            "Testing Acc.: 0.9505000025033951\n",
            "Epoch 518 completed, average training loss is 0.18596861688420177\n",
            "Testing Acc.: 0.9513000029325486\n",
            "Epoch 519 completed, average training loss is 0.15729603039100767\n",
            "Testing Acc.: 0.9518000030517578\n",
            "Epoch 520 completed, average training loss is 0.14247367050498724\n",
            "Testing Acc.: 0.9535000056028367\n",
            "Epoch 521 completed, average training loss is 0.15966228070358435\n",
            "Testing Acc.: 0.9498000019788742\n",
            "Epoch 522 completed, average training loss is 0.13485547027240197\n",
            "Testing Acc.: 0.9521000021696091\n",
            "Epoch 523 completed, average training loss is 0.1379677476019909\n",
            "Testing Acc.: 0.9514000022411346\n",
            "Epoch 524 completed, average training loss is 0.1320956070162356\n",
            "Testing Acc.: 0.951100001335144\n",
            "Epoch 525 completed, average training loss is 0.14632825709258518\n",
            "Testing Acc.: 0.9510000014305114\n",
            "Epoch 526 completed, average training loss is 0.18224061078081527\n",
            "Testing Acc.: 0.9510000014305114\n",
            "Epoch 527 completed, average training loss is 0.16314107816045484\n",
            "Testing Acc.: 0.9523000013828278\n",
            "Epoch 528 completed, average training loss is 0.13279817221065363\n",
            "Testing Acc.: 0.9522000062465668\n",
            "Epoch 529 completed, average training loss is 0.12750406404336292\n",
            "Testing Acc.: 0.9521000027656555\n",
            "Epoch 530 completed, average training loss is 0.1346916533478846\n",
            "Testing Acc.: 0.9518000066280365\n",
            "Epoch 531 completed, average training loss is 0.14557651627187929\n",
            "Testing Acc.: 0.9499000030755996\n",
            "Epoch 532 completed, average training loss is 0.12756481596889596\n",
            "Testing Acc.: 0.9516000026464462\n",
            "Epoch 533 completed, average training loss is 0.1352850218831251\n",
            "Testing Acc.: 0.9524000042676926\n",
            "Epoch 534 completed, average training loss is 0.13356124816151957\n",
            "Testing Acc.: 0.95230000436306\n",
            "Epoch 535 completed, average training loss is 0.1648745535686612\n",
            "Testing Acc.: 0.9492000049352646\n",
            "Epoch 536 completed, average training loss is 0.1985697322959701\n",
            "Testing Acc.: 0.9489000052213669\n",
            "Epoch 537 completed, average training loss is 0.1599104851608475\n",
            "Testing Acc.: 0.9520000022649765\n",
            "Epoch 538 completed, average training loss is 0.14972417478139202\n",
            "Testing Acc.: 0.9519000029563904\n",
            "Epoch 539 completed, average training loss is 0.1747201739065349\n",
            "Testing Acc.: 0.9514000058174134\n",
            "Epoch 540 completed, average training loss is 0.15055421027665336\n",
            "Testing Acc.: 0.9516000020503997\n",
            "Epoch 541 completed, average training loss is 0.13527088878055413\n",
            "Testing Acc.: 0.9509000021219254\n",
            "Epoch 542 completed, average training loss is 0.1278692606681337\n",
            "Testing Acc.: 0.9520000016689301\n",
            "Epoch 543 completed, average training loss is 0.12920917777965465\n",
            "Testing Acc.: 0.953100003004074\n",
            "Epoch 544 completed, average training loss is 0.1265999291681995\n",
            "Testing Acc.: 0.9505000019073486\n",
            "Epoch 545 completed, average training loss is 0.12752879910171033\n",
            "Testing Acc.: 0.9505000025033951\n",
            "Epoch 546 completed, average training loss is 0.16183683424567183\n",
            "Testing Acc.: 0.9527000051736831\n",
            "Epoch 547 completed, average training loss is 0.16607342215254903\n",
            "Testing Acc.: 0.9511000019311905\n",
            "Epoch 548 completed, average training loss is 0.14852716498076915\n",
            "Testing Acc.: 0.9527000027894974\n",
            "Epoch 549 completed, average training loss is 0.13159052674348157\n",
            "Testing Acc.: 0.9515000039339065\n",
            "Epoch 550 completed, average training loss is 0.12959201594193775\n",
            "Testing Acc.: 0.9523000019788742\n",
            "Epoch 551 completed, average training loss is 0.1256747217910985\n",
            "Testing Acc.: 0.9524000024795533\n",
            "Epoch 552 completed, average training loss is 0.12987401599995793\n",
            "Testing Acc.: 0.9517000025510788\n",
            "Epoch 553 completed, average training loss is 0.12544559820865592\n",
            "Testing Acc.: 0.9490000057220459\n",
            "Epoch 554 completed, average training loss is 0.1790951840331157\n",
            "Testing Acc.: 0.9514000022411346\n",
            "Epoch 555 completed, average training loss is 0.15340717397630216\n",
            "Testing Acc.: 0.9524000030755997\n",
            "Epoch 556 completed, average training loss is 0.12773072774211566\n",
            "Testing Acc.: 0.951800001859665\n",
            "Epoch 557 completed, average training loss is 0.13068479555969437\n",
            "Testing Acc.: 0.9517000043392181\n",
            "Epoch 558 completed, average training loss is 0.12609240623811882\n",
            "Testing Acc.: 0.9517000037431717\n",
            "Epoch 559 completed, average training loss is 0.12708512595544258\n",
            "Testing Acc.: 0.9514000016450882\n",
            "Epoch 560 completed, average training loss is 0.15207536664480964\n",
            "Testing Acc.: 0.9534000039100647\n",
            "Epoch 561 completed, average training loss is 0.145131776832665\n",
            "Testing Acc.: 0.9525000017881393\n",
            "Epoch 562 completed, average training loss is 0.14942832524577776\n",
            "Testing Acc.: 0.9522000050544739\n",
            "Epoch 563 completed, average training loss is 0.14855198040604592\n",
            "Testing Acc.: 0.95230000436306\n",
            "Epoch 564 completed, average training loss is 0.13050445731418828\n",
            "Testing Acc.: 0.9523000061511994\n",
            "Epoch 565 completed, average training loss is 0.15280251197516917\n",
            "Testing Acc.: 0.9520000058412552\n",
            "Epoch 566 completed, average training loss is 0.16216578597823778\n",
            "Testing Acc.: 0.950400003194809\n",
            "Epoch 567 completed, average training loss is 0.14060381124416987\n",
            "Testing Acc.: 0.9506000047922134\n",
            "Epoch 568 completed, average training loss is 0.1302784749120474\n",
            "Testing Acc.: 0.952200003862381\n",
            "Epoch 569 completed, average training loss is 0.12494823374164601\n",
            "Testing Acc.: 0.9515000021457672\n",
            "Epoch 570 completed, average training loss is 0.1250777431887885\n",
            "Testing Acc.: 0.9523000031709671\n",
            "Epoch 571 completed, average training loss is 0.12684420090168713\n",
            "Testing Acc.: 0.9520000022649765\n",
            "Epoch 572 completed, average training loss is 0.1514946796062092\n",
            "Testing Acc.: 0.9517000037431717\n",
            "Epoch 573 completed, average training loss is 0.14477339643985032\n",
            "Testing Acc.: 0.9496000033617019\n",
            "Epoch 574 completed, average training loss is 0.13175061595936616\n",
            "Testing Acc.: 0.9535000056028367\n",
            "Epoch 575 completed, average training loss is 0.14537729030475022\n",
            "Testing Acc.: 0.9527000027894974\n",
            "Epoch 576 completed, average training loss is 0.12588062694917124\n",
            "Testing Acc.: 0.9517000037431717\n",
            "Epoch 577 completed, average training loss is 0.15535409870867928\n",
            "Testing Acc.: 0.9518000054359436\n",
            "Epoch 578 completed, average training loss is 0.14956335396816334\n",
            "Testing Acc.: 0.9503000062704087\n",
            "Epoch 579 completed, average training loss is 0.18058962230881057\n",
            "Testing Acc.: 0.953100003004074\n",
            "Epoch 580 completed, average training loss is 0.14721098917846878\n",
            "Testing Acc.: 0.9514000022411346\n",
            "Epoch 581 completed, average training loss is 0.12700202359507481\n",
            "Testing Acc.: 0.952200003862381\n",
            "Epoch 582 completed, average training loss is 0.12837761313964924\n",
            "Testing Acc.: 0.9516000026464462\n",
            "Epoch 583 completed, average training loss is 0.15811382298668225\n",
            "Testing Acc.: 0.9514000064134598\n",
            "Epoch 584 completed, average training loss is 0.15768329589317243\n",
            "Testing Acc.: 0.9507000029087067\n",
            "Epoch 585 completed, average training loss is 0.1677063872292638\n",
            "Testing Acc.: 0.9499000030755996\n",
            "Epoch 586 completed, average training loss is 0.16561682372664413\n",
            "Testing Acc.: 0.9526000040769577\n",
            "Epoch 587 completed, average training loss is 0.13748986841800312\n",
            "Testing Acc.: 0.9505000007152558\n",
            "Epoch 588 completed, average training loss is 0.12682781722707054\n",
            "Testing Acc.: 0.9511000031232834\n",
            "Epoch 589 completed, average training loss is 0.1240426850070556\n",
            "Testing Acc.: 0.9521000021696091\n",
            "Epoch 590 completed, average training loss is 0.12969488881528377\n",
            "Testing Acc.: 0.9518000036478043\n",
            "Epoch 591 completed, average training loss is 0.14841830380260945\n",
            "Testing Acc.: 0.9510000020265579\n",
            "Epoch 592 completed, average training loss is 0.13089958311679462\n",
            "Testing Acc.: 0.9502000039815903\n",
            "Epoch 593 completed, average training loss is 0.13984547186642884\n",
            "Testing Acc.: 0.951600005030632\n",
            "Epoch 594 completed, average training loss is 0.15972458579887946\n",
            "Testing Acc.: 0.9521000039577484\n",
            "Epoch 595 completed, average training loss is 0.13977064710731307\n",
            "Testing Acc.: 0.9512000036239624\n",
            "Epoch 596 completed, average training loss is 0.12362873517908156\n",
            "Testing Acc.: 0.9524000042676926\n",
            "Epoch 597 completed, average training loss is 0.13160444829612972\n",
            "Testing Acc.: 0.951100001335144\n",
            "Epoch 598 completed, average training loss is 0.1631831302928428\n",
            "Testing Acc.: 0.9524000036716461\n",
            "Epoch 599 completed, average training loss is 0.1467617541241149\n",
            "Testing Acc.: 0.9512000060081482\n",
            "Epoch 600 completed, average training loss is 0.14485914540166656\n",
            "Testing Acc.: 0.9528000026941299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09eac735-335a-428b-9ab8-cd8f3857595f",
        "id": "e25ae752tx7E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy_bin_rate(5000)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Acc.: 0.9528000026941299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "262efaC05e0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bf37501-f738-4028-afca-7d94d6161789"
      },
      "source": [
        "# Save model, for not having to fully retrain it each time.\n",
        "saver = tf.train.Saver()\n",
        "saver.save(sess, 'maxpool/model.ckpt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'maxpool/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGK5h5-X5mh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "123b7ac3-42ce-4b74-f150-538331f737f3"
      },
      "source": [
        "!zip -r maxpool.zip maxpool"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: maxpool/ (stored 0%)\n",
            "  adding: maxpool/checkpoint (deflated 42%)\n",
            "  adding: maxpool/model.ckpt.index (deflated 44%)\n",
            "  adding: maxpool/model.ckpt.data-00000-of-00001 (deflated 12%)\n",
            "  adding: maxpool/model.ckpt.meta (deflated 87%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a92e7c09-56c4-441a-b2fa-a992a6c2eef7",
        "id": "lNEFZaVotx7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Rounding operation\n",
        "rounding_weights1_op = tf.assign(w1, \n",
        "                          tf.round(w1/ROUNDING_STEP_CONV)*ROUNDING_STEP_CONV)\n",
        "rounding_bias1_op = tf.assign(b1,\n",
        "                          tf.round(b1/ROUNDING_STEP_BIAS)*ROUNDING_STEP_BIAS)\n",
        "rounding_weights2_op = tf.assign(w2, \n",
        "                          tf.round(w2/ROUNDING_STEP_CONV)*ROUNDING_STEP_CONV)\n",
        "rounding_t_op = tf.assign(thresh,\n",
        "                          tf.round(thresh/ROUNDING_STEP_BIAS)*ROUNDING_STEP_BIAS)\n",
        "\n",
        "_ = sess.run([rounding_weights1_op, rounding_bias1_op])\n",
        "_ = sess.run([rounding_weights2_op, rounding_t_op])\n",
        "\n",
        "# Accuracy with rounded weights:\n",
        "test_accuracy_bin_rate(5000)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Acc.: 0.9417000025510788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "026dd992-20c2-4742-9b0b-c6a206a6e7e5",
        "id": "tQNA3tm6tx7h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Show distribution of weights after rounding\n",
        "w1_values, b1_values = sess.run([w1, b1])\n",
        "w2_values = sess.run(w2)\n",
        "thresh_values = sess.run(thresh)\n",
        "\n",
        "kernel_values = (list(w1_values.flatten()) + list(b1_values.flatten())\n",
        "                + list(w2_values.flatten())\n",
        "                + list(thresh_values.flatten()) )\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.scatter(kernel_values, [1]*len(kernel_values))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fdf36702ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIElqDARJEgD/H7zin+REu9OOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONv8S2hK5ylr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('NP_WEIGHTS.pck', 'wb') as f:\n",
        "  pickle.dump((w1_values, b1_values, w2_values, thresh_values), f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GmRYltDitx70"
      },
      "source": [
        "## 1.3 Retraining only FC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8YTBkjutx71",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope('dense1', reuse=True) as scope_conv:\n",
        "  fc1_k = tf.get_variable('kernel')\n",
        "  fc1_b = tf.get_variable('bias')\n",
        "\n",
        "with tf.variable_scope('dense2', reuse=True) as scope_conv:\n",
        "  fc2_k = tf.get_variable('kernel')\n",
        "  fc2_b = tf.get_variable('bias')\n",
        "\n",
        "opt_only_fc_op = opt_with_reg.minimize(loss_op, var_list=[fc1_k, fc1_b,\n",
        "                                                          fc2_k, fc2_b])\n",
        "\n",
        "sess.run(tf.variables_initializer(opt_with_reg.variables()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3c4b2809-e73c-4520-9a59-742d5b8e842d",
        "id": "19r1x4sitx74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bin_rate_feed = MAX_BIN_RATE + 1\n",
        "\n",
        "for epoch in range(EPOCHS*2):\n",
        "  if epoch < EPOCHS:\n",
        "    lr_feed = LR\n",
        "  else:\n",
        "    lr_feed = LR / 4.\n",
        "\n",
        "  random_perm = np.random.permutation(x_train.shape[0])\n",
        "  losses = np.zeros(x_train.shape[0] // BATCH_SIZE)\n",
        "  for i in range(x_train.shape[0] // BATCH_SIZE):\n",
        "    start = i * BATCH_SIZE\n",
        "    stop = start + BATCH_SIZE\n",
        "    selected = random_perm[start:stop]\n",
        "\n",
        "    xs = np.expand_dims(x_train[selected],-1)\n",
        "    ys = y_train[selected]\n",
        "\n",
        "    _, current_loss = sess.run([opt_only_fc_op, loss_op],\n",
        "                       feed_dict={in_image_ph: xs,\n",
        "                                  gt_label_ph: ys,\n",
        "                                  lr_ph: lr_feed,\n",
        "                                  bin_rate_ph: bin_rate_feed})\n",
        "\n",
        "    losses[i] = current_loss\n",
        "\n",
        "  print('Epoch {} completed, average training loss is {}'.format(\n",
        "          epoch+1, losses.mean()))\n",
        "  test_accuracy_bin_rate(bin_rate_feed)\n",
        "\n",
        "test_acc_after_fc_retrain = test_accuracy_bin_rate(MAX_BIN_RATE + 1)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed, average training loss is 0.13468369495434065\n",
            "Testing Acc.: 0.9516000062227249\n",
            "Epoch 2 completed, average training loss is 0.13285441918298602\n",
            "Testing Acc.: 0.9514000052213669\n",
            "Epoch 3 completed, average training loss is 0.1323116242295752\n",
            "Testing Acc.: 0.9498000031709671\n",
            "Epoch 4 completed, average training loss is 0.13214120538284382\n",
            "Testing Acc.: 0.9484000033140183\n",
            "Epoch 5 completed, average training loss is 0.13335040671440462\n",
            "Testing Acc.: 0.947200003862381\n",
            "Epoch 6 completed, average training loss is 0.13332526868830125\n",
            "Testing Acc.: 0.9438000041246414\n",
            "Epoch 7 completed, average training loss is 0.1328279864555225\n",
            "Testing Acc.: 0.9514000052213669\n",
            "Epoch 8 completed, average training loss is 0.13234003456309437\n",
            "Testing Acc.: 0.951300003528595\n",
            "Epoch 9 completed, average training loss is 0.13320355685738225\n",
            "Testing Acc.: 0.9493000042438507\n",
            "Epoch 10 completed, average training loss is 0.13297378891768555\n",
            "Testing Acc.: 0.9501000046730042\n",
            "Epoch 11 completed, average training loss is 0.1313356720780333\n",
            "Testing Acc.: 0.9484000039100647\n",
            "Epoch 12 completed, average training loss is 0.1311758933092157\n",
            "Testing Acc.: 0.9481000053882599\n",
            "Epoch 13 completed, average training loss is 0.1323185628745705\n",
            "Testing Acc.: 0.948700001835823\n",
            "Epoch 14 completed, average training loss is 0.13142907119976976\n",
            "Testing Acc.: 0.9528000038862229\n",
            "Epoch 15 completed, average training loss is 0.13035131925406554\n",
            "Testing Acc.: 0.9503000038862228\n",
            "Epoch 16 completed, average training loss is 0.132605270507435\n",
            "Testing Acc.: 0.9488000047206878\n",
            "Epoch 17 completed, average training loss is 0.13090754290111362\n",
            "Testing Acc.: 0.9475000029802323\n",
            "Epoch 18 completed, average training loss is 0.13027126286489268\n",
            "Testing Acc.: 0.9487000066041946\n",
            "Epoch 19 completed, average training loss is 0.1306577791677167\n",
            "Testing Acc.: 0.9508000028133392\n",
            "Epoch 20 completed, average training loss is 0.13129522149451078\n",
            "Testing Acc.: 0.9493000030517578\n",
            "Epoch 21 completed, average training loss is 0.12981212976078194\n",
            "Testing Acc.: 0.9458000057935715\n",
            "Epoch 22 completed, average training loss is 0.13093174745328726\n",
            "Testing Acc.: 0.9499000024795532\n",
            "Epoch 23 completed, average training loss is 0.1299069068580866\n",
            "Testing Acc.: 0.9508000040054321\n",
            "Epoch 24 completed, average training loss is 0.13082075421698391\n",
            "Testing Acc.: 0.9494000029563904\n",
            "Epoch 25 completed, average training loss is 0.1309239331788073\n",
            "Testing Acc.: 0.9496000057458878\n",
            "Epoch 26 completed, average training loss is 0.1289640301745385\n",
            "Testing Acc.: 0.9487000036239625\n",
            "Epoch 27 completed, average training loss is 0.12958877162386973\n",
            "Testing Acc.: 0.9520000046491623\n",
            "Epoch 28 completed, average training loss is 0.12981448837866386\n",
            "Testing Acc.: 0.9487000054121018\n",
            "Epoch 29 completed, average training loss is 0.12961857160863777\n",
            "Testing Acc.: 0.949000004529953\n",
            "Epoch 30 completed, average training loss is 0.1307046429781864\n",
            "Testing Acc.: 0.9506000053882598\n",
            "Epoch 31 completed, average training loss is 0.13022376329638063\n",
            "Testing Acc.: 0.9478000020980835\n",
            "Epoch 32 completed, average training loss is 0.1294923538311074\n",
            "Testing Acc.: 0.94980000436306\n",
            "Epoch 33 completed, average training loss is 0.1308583134971559\n",
            "Testing Acc.: 0.9507000041007996\n",
            "Epoch 34 completed, average training loss is 0.12842541049855452\n",
            "Testing Acc.: 0.9490000015497208\n",
            "Epoch 35 completed, average training loss is 0.12890108870342373\n",
            "Testing Acc.: 0.9498000019788742\n",
            "Epoch 36 completed, average training loss is 0.12842086549537876\n",
            "Testing Acc.: 0.9497000050544738\n",
            "Epoch 37 completed, average training loss is 0.12846693904449544\n",
            "Testing Acc.: 0.9511000049114228\n",
            "Epoch 38 completed, average training loss is 0.12905191680726905\n",
            "Testing Acc.: 0.9506000036001205\n",
            "Epoch 39 completed, average training loss is 0.1282502849896749\n",
            "Testing Acc.: 0.9483000010251998\n",
            "Epoch 40 completed, average training loss is 0.12882525546786686\n",
            "Testing Acc.: 0.9505000030994415\n",
            "Epoch 41 completed, average training loss is 0.1275329357696076\n",
            "Testing Acc.: 0.9487000036239625\n",
            "Epoch 42 completed, average training loss is 0.1279986210912466\n",
            "Testing Acc.: 0.9496000033617019\n",
            "Epoch 43 completed, average training loss is 0.12870875011819105\n",
            "Testing Acc.: 0.9489000016450881\n",
            "Epoch 44 completed, average training loss is 0.1279383901723971\n",
            "Testing Acc.: 0.9515000063180924\n",
            "Epoch 45 completed, average training loss is 0.12796453068964184\n",
            "Testing Acc.: 0.9489000022411347\n",
            "Epoch 46 completed, average training loss is 0.12734715533442795\n",
            "Testing Acc.: 0.9501000046730042\n",
            "Epoch 47 completed, average training loss is 0.12743775567039847\n",
            "Testing Acc.: 0.9487000054121018\n",
            "Epoch 48 completed, average training loss is 0.12721580997109413\n",
            "Testing Acc.: 0.9500000023841858\n",
            "Epoch 49 completed, average training loss is 0.12823251326568424\n",
            "Testing Acc.: 0.9508000022172928\n",
            "Epoch 50 completed, average training loss is 0.12682232536375523\n",
            "Testing Acc.: 0.9492000037431717\n",
            "Epoch 51 completed, average training loss is 0.11726376886169115\n",
            "Testing Acc.: 0.95030000269413\n",
            "Epoch 52 completed, average training loss is 0.1162905795313418\n",
            "Testing Acc.: 0.9501000046730042\n",
            "Epoch 53 completed, average training loss is 0.11637211861088873\n",
            "Testing Acc.: 0.9508000040054321\n",
            "Epoch 54 completed, average training loss is 0.11596409872484705\n",
            "Testing Acc.: 0.9501000052690506\n",
            "Epoch 55 completed, average training loss is 0.1160713677511861\n",
            "Testing Acc.: 0.9514000052213669\n",
            "Epoch 56 completed, average training loss is 0.11630306866951287\n",
            "Testing Acc.: 0.9498000037670136\n",
            "Epoch 57 completed, average training loss is 0.1157706442878892\n",
            "Testing Acc.: 0.9513000053167343\n",
            "Epoch 58 completed, average training loss is 0.11591934741474688\n",
            "Testing Acc.: 0.9515000051259994\n",
            "Epoch 59 completed, average training loss is 0.11598901748657227\n",
            "Testing Acc.: 0.9498000055551529\n",
            "Epoch 60 completed, average training loss is 0.11562638198646406\n",
            "Testing Acc.: 0.9507000052928924\n",
            "Epoch 61 completed, average training loss is 0.11538315116738279\n",
            "Testing Acc.: 0.9511000061035156\n",
            "Epoch 62 completed, average training loss is 0.1159270371713986\n",
            "Testing Acc.: 0.9522000074386596\n",
            "Epoch 63 completed, average training loss is 0.11583240989906092\n",
            "Testing Acc.: 0.9511000031232834\n",
            "Epoch 64 completed, average training loss is 0.11538543494418263\n",
            "Testing Acc.: 0.9510000026226044\n",
            "Epoch 65 completed, average training loss is 0.11574579016615948\n",
            "Testing Acc.: 0.9503000038862228\n",
            "Epoch 66 completed, average training loss is 0.11555646195386847\n",
            "Testing Acc.: 0.9503000044822693\n",
            "Epoch 67 completed, average training loss is 0.1158501391361157\n",
            "Testing Acc.: 0.951500004529953\n",
            "Epoch 68 completed, average training loss is 0.11544671016434828\n",
            "Testing Acc.: 0.9505000048875809\n",
            "Epoch 69 completed, average training loss is 0.11547087891958654\n",
            "Testing Acc.: 0.950000005364418\n",
            "Epoch 70 completed, average training loss is 0.11546049746374289\n",
            "Testing Acc.: 0.9505000042915345\n",
            "Epoch 71 completed, average training loss is 0.11538004403623442\n",
            "Testing Acc.: 0.9509000039100647\n",
            "Epoch 72 completed, average training loss is 0.115640567454199\n",
            "Testing Acc.: 0.9514000022411346\n",
            "Epoch 73 completed, average training loss is 0.11557262532102565\n",
            "Testing Acc.: 0.94930000603199\n",
            "Epoch 74 completed, average training loss is 0.1154439383931458\n",
            "Testing Acc.: 0.9495000034570694\n",
            "Epoch 75 completed, average training loss is 0.11538097490556538\n",
            "Testing Acc.: 0.9511000019311905\n",
            "Epoch 76 completed, average training loss is 0.11509292773281535\n",
            "Testing Acc.: 0.9504000037908554\n",
            "Epoch 77 completed, average training loss is 0.1151638611809661\n",
            "Testing Acc.: 0.950700004696846\n",
            "Epoch 78 completed, average training loss is 0.11525918144111832\n",
            "Testing Acc.: 0.9491000026464462\n",
            "Epoch 79 completed, average training loss is 0.11530117790525159\n",
            "Testing Acc.: 0.9515000051259994\n",
            "Epoch 80 completed, average training loss is 0.11533652238237362\n",
            "Testing Acc.: 0.9505000048875809\n",
            "Epoch 81 completed, average training loss is 0.11500425382517278\n",
            "Testing Acc.: 0.9504000055789947\n",
            "Epoch 82 completed, average training loss is 0.11499836444389075\n",
            "Testing Acc.: 0.94980000436306\n",
            "Epoch 83 completed, average training loss is 0.1151673676725477\n",
            "Testing Acc.: 0.9493000036478043\n",
            "Epoch 84 completed, average training loss is 0.11536335092348357\n",
            "Testing Acc.: 0.9477000039815903\n",
            "Epoch 85 completed, average training loss is 0.1150879958209892\n",
            "Testing Acc.: 0.9501000034809113\n",
            "Epoch 86 completed, average training loss is 0.11492563205460707\n",
            "Testing Acc.: 0.9510000056028366\n",
            "Epoch 87 completed, average training loss is 0.11501319740898908\n",
            "Testing Acc.: 0.9482000052928925\n",
            "Epoch 88 completed, average training loss is 0.11498017297126353\n",
            "Testing Acc.: 0.9503000038862228\n",
            "Epoch 89 completed, average training loss is 0.1148731424814711\n",
            "Testing Acc.: 0.9508000046014786\n",
            "Epoch 90 completed, average training loss is 0.11488781085393081\n",
            "Testing Acc.: 0.950400003194809\n",
            "Epoch 91 completed, average training loss is 0.11471950776875019\n",
            "Testing Acc.: 0.9508000046014786\n",
            "Epoch 92 completed, average training loss is 0.11473134032140175\n",
            "Testing Acc.: 0.9507000035047531\n",
            "Epoch 93 completed, average training loss is 0.11490848896404107\n",
            "Testing Acc.: 0.9499000054597855\n",
            "Epoch 94 completed, average training loss is 0.11508602513621251\n",
            "Testing Acc.: 0.9509000027179718\n",
            "Epoch 95 completed, average training loss is 0.11465057976233463\n",
            "Testing Acc.: 0.9498000031709671\n",
            "Epoch 96 completed, average training loss is 0.11471121212467551\n",
            "Testing Acc.: 0.9518000048398971\n",
            "Epoch 97 completed, average training loss is 0.11486973296850919\n",
            "Testing Acc.: 0.948900004029274\n",
            "Epoch 98 completed, average training loss is 0.11466717612929642\n",
            "Testing Acc.: 0.950700004696846\n",
            "Epoch 99 completed, average training loss is 0.11480185687541962\n",
            "Testing Acc.: 0.951200003027916\n",
            "Epoch 100 completed, average training loss is 0.11456319948347907\n",
            "Testing Acc.: 0.9491000044345855\n",
            "Testing Acc.: 0.9491000044345855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19f81729-3013-4b1b-b57f-e204126ab250",
        "id": "nYASjGmWtx8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_accuracy_bin_rate(5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Acc.: 0.8299999982118607\n",
            "Testing Acc.: 0.8299999982118607\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retraining FC layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "v4iP7MEtFPvu",
        "-OcAFV3cdAex"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg-uPbWI-Kog",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we load what was captured by the SCAMP5 host application when the camera was shown MNIST data. We use this to retrain the fully connected layers, taking noise into account.\n",
        " * Parse the .txt file to create numpy training/testing data. It also saved as .pck, for not having to re-parse the file each time.\n",
        " * This data is then used to train fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yT69IUbpCWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpl_AYFB_JT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Partial MNIST by AnalogNet: 100 examples for each digit in each subset (train/test)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190628_1735_33_reencoded.TXT'\n",
        "\n",
        "# Whole MNIST capture by AnalogNet\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190702_1750.txt'\n",
        "#-> 92.6% testing acc with legacy training\n",
        "#-> 93.8% testing acc with long training\n",
        "#-> 93.9% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by AnalogNet, with 12 bins instead of 9 (new pooling)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190714_1101.txt'\n",
        "# -> 96.4% testing acc with legacy training\n",
        "# -> 96.8% testing acc with long/very long training\n",
        "\n",
        "# Whole MNIST capture by AnalogNet, with 12 bins instead of 9, and no\n",
        "# overlapping between bins\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190718_0030.txt'\n",
        "# -> 96.3% testing acc with legacy training\n",
        "# -> 96.7% testing acc with long training\n",
        "# -> 96.6% testing acc with very long training\n",
        "\n",
        "\n",
        "\n",
        "# Whole MNIST capture by 3 quantise 3\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190712_2041.txt'\n",
        "#-> gives 91.9% testing acc with 2 layers, ReLU, very long training...\n",
        "\n",
        "# Whole MNIST capture by 3 quantise 3, with 150 collected events per feature map\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190714_0030.txt'\n",
        "#-> gives 92.7% testing acc with 2 layers, long training.\n",
        "#-> 93.2% testing acc with 2 layers, very long training\n",
        "\n",
        "# Whole MNIST capture by 3 quantise 3, with 150 collected events per feature map,\n",
        "# and 12 bins instead of 9 (new pooling)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190715_0000_38.txt'\n",
        "# -> 94.6% testing acc with legacy training\n",
        "# -> 95.7% testing acc with long training\n",
        "# -> 95.8% testing acc with very long training\n",
        "\n",
        "\n",
        "\n",
        "# Whole MNIST capture by 4 maxpool 8\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190717_0042.txt'\n",
        "# -> 91.9% testing acc with legacy training\n",
        "# -> 92.6% testing acc with long training\n",
        "# -> 92.9% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by 4 maxpool 8 bis (debugged)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190731_2346.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 92.9% testing acc with very long training\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "# Depth separable convolutions, accumulation\n",
        "\n",
        "# Whole MNIST capture by one layer (similar to AnalogNet, slightly\n",
        "# different register managmenent)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190719_0106.txt'\n",
        "# -> 96.2% testing acc with legacy training\n",
        "# -> 96.8% testing acc with long training\n",
        "# -> 96.9% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by two layers of depth separable conv, with leaky ReLU (.25)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190726_0022.txt'\n",
        "# -> 93.4% testing acc with legacy training\n",
        "# -> 94.7% testing acc with long training\n",
        "# -> 94.4% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by three layers of depth separable conv, with leaky ReLU (.25)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190727_0013.txt'\n",
        "# -> 93.3% testing acc with legacy training\n",
        "# -> 94.1% testing acc with long training\n",
        "# -> 94.4% testing acc with very long training\n",
        "\n",
        "\n",
        "# Whole MNIST capture by four layers of depth separable conv, with leaky ReLU (.25)\n",
        "#RAW_OUTPUT_FILENAME = 'text_log_20190731_0245.txt'\n",
        "# -> 92.0% testing acc with legacy training\n",
        "# -> 93.2% testing acc with long training\n",
        "# -> 93.3% testing acc with very long training\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "# One layer network, with increasingly many kernels\n",
        "\n",
        "# Whole MNIST capture by one layer 1 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out13.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 89.99% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by one layer 2 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out25.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 89.73% testing acc with very long training\n",
        "## -> 93.78% testing acc, when simulating a 2 layers net by truncating a 6 layer one...\n",
        "\n",
        "# Whole MNIST capture by one layer 3 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out37.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 95.81% testing acc with very long training\n",
        "## -> 96.09% testing acc, when simulating a 3 layers net by truncating a 6 layer one...\n",
        "## -> 96.06% testing acc, when simulating a 3 layers net by truncating a 7 layer one...\n",
        "\n",
        "# Whole MNIST capture by one layer 4 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out49.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 96.94% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by one layer 5 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out61.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 97.04% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by one layer 6 kernel\n",
        "RAW_OUTPUT_FILENAME = 'out73.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 97.7% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by one layer 7 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out85.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 98.21% testing acc with very long training\n",
        "\n",
        "# Whole MNIST capture by one layer 8 kernel\n",
        "#RAW_OUTPUT_FILENAME = 'out97.txt'\n",
        "# -> % testing acc with legacy training\n",
        "# -> % testing acc with long training\n",
        "# -> 97.98% testing acc with very long training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi11SvDvefd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 50\n",
        "LR = 0.0001\n",
        "EPOCHS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4iP7MEtFPvu",
        "colab_type": "text"
      },
      "source": [
        "#0. Imports and utils functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V2mS64VFRWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ast\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax419e0ZJiJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_first(item, vec):\n",
        "  '''return the index of the first occurence of item in vec'''\n",
        "  for i in range(len(vec)):\n",
        "      if item == vec[i]:\n",
        "          return i\n",
        "  return len(vec) # Move to the end if item not found"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9DC0NKafCm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_accuracy(verbose=False):\n",
        "  accs = np.zeros(x_test.shape[0] // BATCH_SIZE)\n",
        "  for i in range(x_test.shape[0] // BATCH_SIZE):\n",
        "    start = i * BATCH_SIZE\n",
        "    stop = start + BATCH_SIZE\n",
        "    \n",
        "    xs = x_test[start:stop]\n",
        "    ys = y_test[start:stop, 0]\n",
        "    \n",
        "    current_acc = sess.run(acc_op,\n",
        "                       feed_dict={in_data_ph: xs,\n",
        "                                  gt_label_ph: ys})\n",
        "    accs[i] = current_acc\n",
        "  \n",
        "  if verbose:\n",
        "      print('Testing Acc.: {}'.format(\n",
        "        accs.mean()))\n",
        "      \n",
        "  return accs.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joLhXKYW-wVO",
        "colab_type": "text"
      },
      "source": [
        "# 1. Parse the raw .txt output file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frfLcSDw_Lh5",
        "colab_type": "text"
      },
      "source": [
        "Structure of the file:\n",
        "\n",
        "* garbage...\n",
        "* garbage...\n",
        "* garbage...\n",
        "* [garbage too]\n",
        "* [garbage starting with 0 or 1]\n",
        "* [10, training 0s]\n",
        "* [garbage starting with 0 or 1]\n",
        "* [10, testing 0s]\n",
        "* [garbage starting with 0 or 1]\n",
        "* [10, training 1s]\n",
        "* [garbage starting with 0 or 1]\n",
        "* [10, testing 1s]\n",
        "...\n",
        "* [10, testing 9s]\n",
        "* [garbage starting with 0 or 1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lGVOhOy-zuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listedContent = []\n",
        "with open(RAW_OUTPUT_FILENAME, 'r+') as f:\n",
        "  for line in f:\n",
        "    if line[0] == '[':\n",
        "      listedContent.append(ast.literal_eval(line))\n",
        "raw_output = np.array(listedContent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGtv8eYbFsEM",
        "colab_type": "code",
        "outputId": "9d4acb35-94fa-40f7-c80e-3c193809ab0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(raw_output[:,0])\n",
        "plt.show\n",
        "# This should show the aforementioned alternating pattern"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdR-mxDINF1C",
        "colab_type": "code",
        "outputId": "831d1062-69b1-4c5e-b43b-8cbaade70cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Special case, for out61.txt and out73.txt datasets\n",
        "# DO NOT EXECUTE OTHERWISE !\n",
        "if RAW_OUTPUT_FILENAME == 'out61.txt' or RAW_OUTPUT_FILENAME == 'out73.txt':\n",
        "  l = raw_output[:,0]\n",
        "  K = -1\n",
        "  for i in range(l.shape[0] - 2):\n",
        "    if l[i-1] < 10 and l[i] == 10 and l[i+1] >= 2 and l[i+2] < 2:\n",
        "      print(i)\n",
        "      K = i\n",
        "  if K >= 0:\n",
        "    raw_output[K,0] = 0\n",
        "    raw_output[K+1,0] = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkH5PCGkI1OF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the starting garbage\n",
        "moveIndex = find_first(10, raw_output[:,0])\n",
        "raw_output = raw_output[moveIndex:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPA38Yq3KCeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingSetX = [0]*10\n",
        "testingSetX = [0]*10\n",
        "trainingSetY = [0]*10\n",
        "testingSetY = [0]*10\n",
        "\n",
        "for i in range(10):\n",
        "  moveIndex = min(find_first(0, raw_output[:,0]), find_first(1, raw_output[:,0]))\n",
        "  trainingSetX[i] = raw_output[:moveIndex,1:]\n",
        "  trainingSetY[i] = i*np.ones((trainingSetX[i].shape[0],1))\n",
        "  \n",
        "  raw_output = raw_output[moveIndex:]\n",
        "  moveIndex = find_first(10, raw_output[:,0])\n",
        "  raw_output = raw_output[moveIndex:]\n",
        "  \n",
        "  moveIndex = min(find_first(0, raw_output[:,0]), find_first(1, raw_output[:,0]))\n",
        "  testingSetX[i] = raw_output[:moveIndex,1:]\n",
        "  testingSetY[i] = i*np.ones((testingSetX[i].shape[0],1))\n",
        "  \n",
        "  raw_output = raw_output[moveIndex:]\n",
        "  moveIndex = find_first(10, raw_output[:,0])\n",
        "  raw_output = raw_output[moveIndex:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BlIxRXGY2T",
        "colab_type": "code",
        "outputId": "a1711d73-41d3-48a3-b562-ef0b448108a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "for label in range(10):\n",
        "  print('Training {0}s: {1}'.format(label, trainingSetX[label].shape[0]))\n",
        "  print('Testing {0}s: {1}'.format(label, testingSetX[label].shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 0s: 11106\n",
            "Testing 0s: 1838\n",
            "Training 1s: 12642\n",
            "Testing 1s: 2128\n",
            "Training 2s: 11172\n",
            "Testing 2s: 1936\n",
            "Training 3s: 11497\n",
            "Testing 3s: 1894\n",
            "Training 4s: 10954\n",
            "Testing 4s: 1842\n",
            "Training 5s: 10165\n",
            "Testing 5s: 1672\n",
            "Training 6s: 11096\n",
            "Testing 6s: 1797\n",
            "Training 7s: 11747\n",
            "Testing 7s: 1928\n",
            "Training 8s: 10972\n",
            "Testing 8s: 1827\n",
            "Training 9s: 11154\n",
            "Testing 9s: 1892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqFLZYMdMXqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.concatenate(trainingSetX)\n",
        "y_train = np.concatenate(trainingSetY)\n",
        "x_test = np.concatenate(testingSetX)\n",
        "y_test = np.concatenate(testingSetY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3YoZWRRNOiM",
        "colab_type": "code",
        "outputId": "f774c263-15e3-41b8-8c2f-bda0adfdadff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Training set input data: {}'.format(x_train.shape))\n",
        "print('Training set labels: {}'.format(y_train.shape))\n",
        "print('Testing set input data: {}'.format(x_test.shape))\n",
        "print('Testing set labels: {}'.format(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set input data: (112505, 72)\n",
            "Training set labels: (112505, 1)\n",
            "Testing set input data: (18754, 72)\n",
            "Testing set labels: (18754, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ShECnzcn7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(((x_train, y_train),(x_test, y_test)),\n",
        "            open(RAW_OUTPUT_FILENAME + '.pck', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OcAFV3cdAex",
        "colab_type": "text"
      },
      "source": [
        "# 2. Train 1 FC layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Pw8776dY6m",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Load data from pickled files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_GhztCgdE4M",
        "colab_type": "code",
        "outputId": "d0750185-c1c1-444d-8187-ec661a58bd9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = pickle.load(\n",
        "                                   open(RAW_OUTPUT_FILENAME + '.pck', 'rb'))\n",
        "\n",
        "print('Training set input data: {}'.format(x_train.shape))\n",
        "print('Training set labels: {}'.format(y_train.shape))\n",
        "print('Testing set input data: {}'.format(x_test.shape))\n",
        "print('Testing set labels: {}'.format(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set input data: (112505, 72)\n",
            "Training set labels: (112505, 1)\n",
            "Testing set input data: (18754, 72)\n",
            "Testing set labels: (18754, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNQeVuGLk9SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.astype(np.uint8)\n",
        "y_test = y_test.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYEozvixeLdF",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Network and graph definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ulGLa6-d1mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network_1fc(input):\n",
        "  out = tf.layers.dense(input, 10, name='dense1')  \n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JJ1t3queWcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "in_data_ph = tf.placeholder(tf.float32, [BATCH_SIZE,72])\n",
        "gt_label_ph = tf.placeholder(tf.uint8)\n",
        "out_label_op = network_1fc(in_data_ph)\n",
        "\n",
        "pred_op = tf.dtypes.cast(\n",
        "            tf.keras.backend.argmax(out_label_op),\n",
        "            tf.uint8)\n",
        "\n",
        "loss_op = tf.reduce_mean(\n",
        "          tf.keras.backend.sparse_categorical_crossentropy(gt_label_ph,\n",
        "                                                           out_label_op,\n",
        "                                                           from_logits=True))\n",
        "\n",
        "acc_op = tf.contrib.metrics.accuracy(gt_label_ph, pred_op)\n",
        "\n",
        "lr_ph = tf.placeholder(tf.float32)\n",
        "opt_op = tf.train.AdamOptimizer(learning_rate=lr_ph).minimize(loss_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOCumIFceOx5",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YG1gkTbeQYb",
        "colab_type": "code",
        "outputId": "50f735ed-6408-4066-ceef-fd7bbc4ed25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  if epoch < EPOCHS/2:\n",
        "    lr_feed = LR\n",
        "  else:\n",
        "    lr_feed = LR/5\n",
        "  random_perm = np.random.permutation(x_train.shape[0])\n",
        "  losses = np.zeros(x_train.shape[0] // BATCH_SIZE)\n",
        "  for i in range(x_train.shape[0] // BATCH_SIZE):\n",
        "    start = i * BATCH_SIZE\n",
        "    stop = start + BATCH_SIZE\n",
        "    selected = random_perm[start:stop]\n",
        "    \n",
        "    xs = x_train[selected]\n",
        "    ys = y_train[selected]\n",
        "    \n",
        "    _, current_loss = sess.run([opt_op, loss_op],\n",
        "                       feed_dict={in_data_ph: xs,\n",
        "                                  gt_label_ph: ys,\n",
        "                                  lr_ph: lr_feed})\n",
        "\n",
        "    losses[i] = current_loss\n",
        "  \n",
        "  if epoch % 20 == 0:\n",
        "    print('Epoch {} completed, average training loss is {}'.format(\n",
        "            epoch+1, losses.mean()))\n",
        "    test_accuracy()\n",
        "test_accuracy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed, average training loss is 6.933345697085063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-a1aab7886646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                        feed_dict={in_data_ph: xs,\n\u001b[1;32m     21\u001b[0m                                   \u001b[0mgt_label_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                   lr_ph: lr_feed})\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nk274qEimOyC"
      },
      "source": [
        "# 3. Train 2 FC layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCQCo2unmOyL"
      },
      "source": [
        "## 3.1 Load data from pickled files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "691dce37-9438-4b8f-9ade-59fd36c14314",
        "id": "PBZbbG5FmOyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = pickle.load(\n",
        "                                   open(RAW_OUTPUT_FILENAME + '.pck', 'rb'))\n",
        "\n",
        "print('Training set input data: {}'.format(x_train.shape))\n",
        "print('Training set labels: {}'.format(y_train.shape))\n",
        "print('Testing set input data: {}'.format(x_test.shape))\n",
        "print('Testing set labels: {}'.format(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set input data: (112521, 84)\n",
            "Training set labels: (112521, 1)\n",
            "Testing set input data: (18754, 84)\n",
            "Testing set labels: (18754, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GX31p1M59mW",
        "colab_type": "code",
        "outputId": "3f3a24ff-2723-4c0b-f28c-c7b5a8f47616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "############### RESTRICT TO FIRST 3 KERNELS\n",
        "\n",
        "x_train = x_train[:,:36]\n",
        "x_test = x_test[:,:36]\n",
        "\n",
        "\n",
        "print('Training set input data: {}'.format(x_train.shape))\n",
        "print('Training set labels: {}'.format(y_train.shape))\n",
        "print('Testing set input data: {}'.format(x_test.shape))\n",
        "print('Testing set labels: {}'.format(y_test.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set input data: (112521, 36)\n",
            "Training set labels: (112521, 1)\n",
            "Testing set input data: (18754, 36)\n",
            "Testing set labels: (18754, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yFj0VDGtmOyh",
        "colab": {}
      },
      "source": [
        "y_train = y_train.astype(np.uint8)\n",
        "y_test = y_test.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tHZdK2ETmOyo"
      },
      "source": [
        "## 3.2 Network and graph definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7wz2sH1fmOyq",
        "colab": {}
      },
      "source": [
        "def network_2fc(input):\n",
        "  fc1 = tf.layers.dense(input, 50, name='dense1', activation=tf.nn.relu)\n",
        "  out = tf.layers.dense(fc1, 10, name='dense2')  \n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7HBmVh77mOyv",
        "outputId": "7ab5b731-cbc0-4ffa-c033-6c149bc26ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "in_data_ph = tf.placeholder(tf.float32, [BATCH_SIZE,36])\n",
        "gt_label_ph = tf.placeholder(tf.uint8)\n",
        "out_label_op = network_2fc(in_data_ph)\n",
        "\n",
        "pred_op = tf.dtypes.cast(\n",
        "            tf.keras.backend.argmax(out_label_op),\n",
        "            tf.uint8)\n",
        "\n",
        "loss_op = tf.reduce_mean(\n",
        "          tf.keras.backend.sparse_categorical_crossentropy(gt_label_ph,\n",
        "                                                           out_label_op,\n",
        "                                                           from_logits=True))\n",
        "\n",
        "acc_op = tf.contrib.metrics.accuracy(gt_label_ph, pred_op)\n",
        "\n",
        "lr_ph = tf.placeholder(tf.float32)\n",
        "opt_op = tf.train.AdamOptimizer(learning_rate=lr_ph).minimize(loss_op)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 14:27:04.759977 140005153736576 deprecation.py:323] From <ipython-input-23-24a71349388f>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0807 14:27:04.770270 140005153736576 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0807 14:27:08.046772 140005153736576 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6YO9vxEomOy0"
      },
      "source": [
        "## 3.3 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "57e3e792-b9d0-4e4a-9d24-cb65f8b7dc51",
        "id": "t-vUgx5qmOy2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\"\"\"\n",
        "# Legacy training, providing 92.6% testing accuracy with AnalogNet data\n",
        "for epoch in range(EPOCHS):\n",
        "  if epoch < EPOCHS/2:\n",
        "    lr_feed = LR\n",
        "  else:\n",
        "    lr_feed = LR/5\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# Longer training -> 91.9% testing accuracy with 3-quantise-3 data\n",
        "for epoch in range(EPOCHS*4):\n",
        "  if epoch < EPOCHS:\n",
        "    lr_feed = LR*4\n",
        "  elif epoch < 2*EPOCHS:\n",
        "    lr_feed = LR * 1.5\n",
        "  elif epoch < 3*EPOCHS:\n",
        "    lr_feed = LR / 2\n",
        "  else:\n",
        "    lr_feed = LR/5\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# Even Longer training\n",
        "for epoch in range(EPOCHS*10):\n",
        "  if epoch < EPOCHS:\n",
        "    lr_feed = LR*8\n",
        "  elif epoch < 3*EPOCHS:\n",
        "    lr_feed = LR * 4\n",
        "  elif epoch < 6*EPOCHS:\n",
        "    lr_feed = LR * 2\n",
        "  elif epoch < 8:\n",
        "    lr_feed = LR\n",
        "  elif epoch < 9:\n",
        "    lr_feed = LR / 2.\n",
        "  else:\n",
        "    lr_feed = LR / 5.\n",
        "\"\"\"\n",
        "max_test_accuracy = 0.\n",
        "for epoch in range(EPOCHS*10):\n",
        "  if epoch < EPOCHS:\n",
        "    lr_feed = LR*8\n",
        "  elif epoch < 3*EPOCHS:\n",
        "    lr_feed = LR * 4\n",
        "  elif epoch < 6*EPOCHS:\n",
        "    lr_feed = LR * 2\n",
        "  elif epoch < 8:\n",
        "    lr_feed = LR\n",
        "  elif epoch < 9:\n",
        "    lr_feed = LR / 2.\n",
        "  else:\n",
        "    lr_feed = LR / 5.\n",
        "  random_perm = np.random.permutation(x_train.shape[0])\n",
        "  losses = np.zeros(x_train.shape[0] // BATCH_SIZE)\n",
        "  for i in range(x_train.shape[0] // BATCH_SIZE):\n",
        "    start = i * BATCH_SIZE\n",
        "    stop = start + BATCH_SIZE\n",
        "    selected = random_perm[start:stop]\n",
        "    \n",
        "    xs = x_train[selected]\n",
        "    ys = y_train[selected, 0]\n",
        "    \n",
        "    _, current_loss = sess.run([opt_op, loss_op],\n",
        "                       feed_dict={in_data_ph: xs,\n",
        "                                  gt_label_ph: ys,\n",
        "                                  lr_ph: lr_feed})\n",
        "\n",
        "    losses[i] = current_loss\n",
        "  \n",
        "  current_test_accuracy = test_accuracy()\n",
        "  \n",
        "  # Save best model\n",
        "  if current_test_accuracy > max_test_accuracy:\n",
        "    saver.save(sess, '2_fc/model.ckpt')\n",
        "    max_test_accuracy = current_test_accuracy\n",
        "  \n",
        "  if epoch % 20 == 0:\n",
        "    print('Epoch {} completed, average training loss is {}'.format(\n",
        "            epoch+1, losses.mean()))\n",
        "    print('Testing Acc.: {}'.format(current_test_accuracy))\n",
        "\n",
        "# Restore best model\n",
        "ckpt = tf.train.get_checkpoint_state('2_fc')\n",
        "saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "_ = test_accuracy(verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed, average training loss is 1.9396354608866904\n",
            "Testing Acc.: 0.8929066642125447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVB_dnmYO1TN",
        "colab_type": "code",
        "outputId": "fa93d45c-8291-40bc-c69e-ad9205e76e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9606400003433228"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUPVeBVJPqtb",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Extract weights, and manually run the FC layers (matrix operations, as on SCAMP5's microcontroller)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amrubPf76SRq",
        "colab_type": "text"
      },
      "source": [
        "### 3.4.1 Weights extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOVcz6ROQl95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[n.name for n in tf.get_default_graph().as_graph_def().node]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBy36kYrP0Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope('dense1', reuse=True) as scope_conv:\n",
        "  fc1_k = tf.get_variable('kernel')\n",
        "  fc1_b = tf.get_variable('bias')\n",
        "\n",
        "with tf.variable_scope('dense2', reuse=True) as scope_conv:\n",
        "  fc2_k = tf.get_variable('kernel')\n",
        "  fc2_b = tf.get_variable('bias')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6yndU2WQK52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc1_k, fc1_b, fc2_k, fc2_b = sess.run([fc1_k, fc1_b, fc2_k, fc2_b])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBQ8DOf46QxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump((fc1_k, fc1_b, fc2_k, fc2_b),\n",
        "            open(RAW_OUTPUT_FILENAME + '_trained_weights_2_fc.pck', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N6dteTBRgnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc1_k, fc1_b, fc2_k, fc2_b = pickle.load(\n",
        "    open(RAW_OUTPUT_FILENAME + '_trained_weights_2_fc.pck', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JPih9kv6kO4",
        "colab_type": "text"
      },
      "source": [
        "### 3.4.2 Compute accuracy when manually running the FC layers (matrix mult)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdAbFN5QpyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_pass(inputVec):\n",
        "  res1 = np.dot(inputVec, fc1_k) + fc1_b\n",
        "  np.maximum(res1, 0, res1)\n",
        "  res2 = np.dot(res1, fc2_k) + fc2_b\n",
        "  return res2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrf9tKGszQku",
        "colab_type": "code",
        "outputId": "9dc79f42-dca5-4383-bd9c-ab2259ea34b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "l = np.array([9, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "print(forward_pass(l))\n",
        "print(fc1_k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -747816.  -221170.   553969. -1400164. -5069166.  3762788. -4552091.\n",
            "  6160486.  -584692. -3187010.]\n",
            "[[-254.  156.   34. ...  149.  -51.   78.]\n",
            " [ -88. -215.    1. ...  -46.  -17. -186.]\n",
            " [  63. -137. -240. ...  169.   24.  -99.]\n",
            " ...\n",
            " [  14.  418. -126. ...  174.   25. -448.]\n",
            " [-510.   75.  156. ...  532.  -13.  553.]\n",
            " [  92.  271.   29. ...   46.   28. -295.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nDrxYF_4Aw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correctPrediction = []\n",
        "for (x, y) in zip(x_test, y_test):\n",
        "  pred = np.argmax(forward_pass(x))\n",
        "  correctPrediction.append(pred == y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuEImhz08A4v",
        "colab_type": "code",
        "outputId": "26402473-52db-45bc-d550-ab933cff74b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.array(correctPrediction).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9692864082910504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4_0XNeEPlka",
        "colab_type": "text"
      },
      "source": [
        "### 3.4.3 Round the weights and compute accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt_PD5wIRBOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRECISION = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUWtJdCX-ZJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc1_k, fc1_b, fc2_k, fc2_b = fc1_k*PRECISION//1, fc1_b*PRECISION//1, fc2_k*PRECISION//1, fc2_b*PRECISION*PRECISION//1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flmVohb5RIMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correctPrediction = []\n",
        "for (x, y) in zip(x_test, y_test):\n",
        "  pred = np.argmax(forward_pass(x))\n",
        "  correctPrediction.append(pred == y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFQRdLxRMH-",
        "colab_type": "code",
        "outputId": "254cc652-3ef6-4df3-d790-a128bcfc71ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.array(correctPrediction).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9691784519054302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUS9lpbLcBSf",
        "colab_type": "code",
        "outputId": "818105b6-1700-448b-d62e-a1e0a8b9c8e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(fc1_k.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}